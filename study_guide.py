import google.genai as genai
import os
import json
import re
from pathlib import Path
from typing import List, Dict, Any
from functools import lru_cache

@lru_cache(maxsize=1)
def _get_api_key() -> str | None:
    """L·∫•y API key t·ª´ env ho·∫∑c Streamlit secrets"""
    key = os.getenv("GEMINI_API_KEY")
    if key:
        return key
    try:
        import streamlit as st
        return st.secrets.get("GEMINI_API_KEY")
    except Exception:
        return None

@lru_cache(maxsize=1)
def _get_study_model():
    """Kh·ªüi t·∫°o model Gemini cho √¥n t·∫≠p"""
    key = _get_api_key()
    if not key:
        print("GEMINI_API_KEY not found")
        return None
    
    try:
        # Create client with API key for google-genai v1.56+
        client = genai.Client(api_key=key)
        return client
    except Exception as e:
        print(f"L·ªói kh·ªüi t·∫°o Study Model: {e}")
        return None

@lru_cache(maxsize=1)
def _get_study_model():
    """Kh·ªüi t·∫°o model Gemini cho √¥n t·∫≠p"""
    key = _get_api_key()
    if not key:
        print("GEMINI_API_KEY not found")
        return None
    
    try:
        # Create client with API key for google-genai v1.56+
        client = genai.Client(api_key=key)
        return client
    except Exception as e:
        print(f"L·ªói kh·ªüi t·∫°o Study Model: {e}")
        return None

def _get_topic_knowledge_base():
    """C∆° s·ªü d·ªØ li·ªáu ki·∫øn th·ª©c chi ti·∫øt cho t·ª´ng topic GMAT"""
    return {
        'Letter Sequence': {
            'theory': '''L√ù THUY·∫æT CHI TI·∫æT V·ªÄ LETTER SEQUENCE (D√£y Ch·ªØ C√°i)

1. ƒê·ªäNH NGHƒ®A:
Letter Sequence l√† d·∫°ng b√†i to√°n y√™u c·∫ßu b·∫°n x√°c ƒë·ªãnh quy lu·∫≠t (pattern) c·ªßa m·ªôt d√£y c√°c ch·ªØ c√°i, sau ƒë√≥ d·ª± ƒëo√°n ch·ªØ c√°i ti·∫øp theo ho·∫∑c t√¨m ki·∫øm ch·ªØ c√°i b·ªã thi·∫øu trong d√£y. Quy lu·∫≠t c√≥ th·ªÉ d·ª±a tr√™n v·ªã tr√≠ ch·ªØ c√°i trong b·∫£ng ch·ªØ c√°i, kho·∫£ng c√°ch gi·ªØa c√°c ch·ªØ, ho·∫∑c k·∫øt h·ª£p c·ªßa nhi·ªÅu y·∫øu t·ªë kh√°c nhau.

2. C√ÅC LO·∫†I PATTERN PH·ªî BI·∫æN:
- PATTERN C√ì ƒêI·ªÄU KI·ªÜN: A, B, C, D, E... (c·ªông 1 trong b·∫£ng ch·ªØ c√°i)
- PATTERN B·ªé QUA: A, C, E, G... (b·ªè qua 1 ch·ªØ c√°i)
- PATTERN N∆Ø·ªöC MU·ªêI: A, A, B, B, C, C... (l·∫∑p l·∫°i m·ªói ch·ªØ 2 l·∫ßn)
- PATTERN N∆Ø·ªöC KI·∫æM: A, B, A, B, C, B, C... (l·∫∑p l·∫°i kh√¥ng ƒë·ªÅu)
- PATTERN KHO·∫¢NG C√ÅCH THAY ƒê·ªîI: A, B, D, G, K... (kho·∫£ng c√°ch c·ªông d·ªìn)
- PATTERN N∆Ø·ªöC NG·ª¢: A, Z, B, Y, C, X... (t·ª´ hai ƒë·∫ßu c·ªßa b·∫£ng ch·ªØ c√°i)

3. C√ÅCH √ÅP D·ª§NG - 4 B∆Ø·ªöC GI·∫¢I:
B∆∞·ªõc 1: X√°c ƒë·ªãnh ch·ªØ c√°i ƒë·∫ßu ti√™n v√† t√≠nh v·ªã tr√≠ trong b·∫£ng ch·ªØ c√°i (A=1, B=2...Z=26)
B∆∞·ªõc 2: T√¨m kho·∫£ng c√°ch/hi·ªáu s·ªë gi·ªØa c√°c ch·ªØ c√°i li√™n ti·∫øp (A‚ÜíB=+1, A‚ÜíC=+2, v.v.)
B∆∞·ªõc 3: Ph√¢n t√≠ch quy lu·∫≠t kho·∫£ng c√°ch (tƒÉng, gi·∫£m, l·∫∑p l·∫°i, hay v√¥ quy t·∫Øc)
B∆∞·ªõc 4: √Åp d·ª•ng quy lu·∫≠t ƒë·ªÉ t√¨m ch·ªØ c√°i ti·∫øp theo

4. V√ç D·ª§ MINH H·ªåA CHI TI·∫æT:
V√≠ d·ª• 1 - Pattern tƒÉng ƒë·ªÅu: A, C, E, G, ?
- A=1, C=3, E=5, G=7
- Quy lu·∫≠t: c·ªông 2 m·ªói l·∫ßn
- ƒê√°p √°n: I=9 (7+2)

V√≠ d·ª• 2 - Pattern kho·∫£ng c√°ch tƒÉng: A, B, D, G, L, ?
- A‚ÜíB: +1, B‚ÜíD: +2, D‚ÜíG: +3, G‚ÜíL: +5... kh√¥ng ph·∫£i, G‚ÜíL l√† +5, v·∫≠y ti·∫øp theo +5? Kh√¥ng ƒë√∫ng
- Ph√¢n t√≠ch l·∫°i: +1, +2, +3, +4... v·∫≠y L+5 = Q

V√≠ d·ª• 3 - Pattern l·∫∑p l·∫°i: A, B, B, C, C, C, ?
- M·ªôt l·∫ßn, hai l·∫ßn, ba l·∫ßn...
- ƒê√°p √°n: D (l·∫∑p 4 l·∫ßn, nh∆∞ng t√≠nh t·ª´ v·ªã tr√≠ ti·∫øp theo)

5. L∆ØU √ù QUAN TR·ªåNG:
- Lu√¥n t√≠nh t·ª´ v·ªã tr√≠ ch·ªØ c√°i trong b·∫£ng (A=1 ƒë·∫øn Z=26), kh√¥ng ph·∫£i v·ªã tr√≠ trong d√£y
- N·∫øu kho·∫£ng c√°ch v∆∞·ª£t qu√° 26 ho·∫∑c nh·ªè h∆°n 1, n√≥ quay v√≤ng: Z+1=A, A-1=Z
- Khi kh√¥ng t√¨m ƒë∆∞·ª£c quy lu·∫≠t tuy·∫øn t√≠nh, h√£y ki·ªÉm tra c√°c pattern ph·ª©c t·∫°p (n∆∞·ªõc mu·ªëi, n∆∞·ªõc ki·∫øm, v.v.)
- Trong b√†i thi GMAT, th∆∞·ªùng ch·ªâ c√≥ 1-2 lo·∫°i pattern, kh√¥ng qu√° ph·ª©c t·∫°p''',
            'detailed_concepts': [
                {
                    'concept_name': 'Kho·∫£ng c√°ch/Hi·ªáu s·ªë (Gap Analysis)',
                    'explanation': 'ƒê√¢y l√† k·ªπ thu·∫≠t c∆° b·∫£n nh·∫•t. T√≠nh hi·ªáu s·ªë (s·ªë l·∫ßn c·ªông th√™m) gi·ªØa m·ªói ch·ªØ c√°i li√™n ti·∫øp. N·∫øu hi·ªáu s·ªë kh√¥ng ƒë·ªïi, d√£y l√† c·∫•p s·ªë c·ªông. N·∫øu hi·ªáu s·ªë thay ƒë·ªïi theo quy lu·∫≠t (tƒÉng/gi·∫£m ƒë·ªÅu), ta c·∫ßn x√°c ƒë·ªãnh quy lu·∫≠t c·ªßa hi·ªáu s·ªë ƒë√≥.',
                    'example': 'A, D, G, J, M, ? ‚Üí Hi·ªáu: +3, +3, +3, +3 ‚Üí ƒê√°p √°n: P (+3)'
                },
                {
                    'concept_name': 'C√°c Pattern ƒê·∫∑c Bi·ªát (Special Patterns)',
                    'explanation': 'Ngo√†i c·∫•p s·ªë c·ªông, c√≤n c√≥ c√°c pattern l·∫∑p l·∫°i (repeating), n∆∞·ªõc mu·ªëi (alternating), hay th·∫≠m ch√≠ k·∫øt h·ª£p ch·ªØ c√°i t·ª´ hai ph√≠a c·ªßa b·∫£ng. H·ªçc sinh c·∫ßn nh·∫≠n di·ªán nhanh c√°c pattern n√†y ƒë·ªÉ kh√¥ng l√£ng ph√≠ th·ªùi gian t√¨m quy lu·∫≠t tuy·∫øn t√≠nh.',
                    'example': 'A, Z, C, X, E, V, ? ‚Üí N∆∞·ªõc mu·ªëi t·ª´ hai ƒë·∫ßu: A(1)‚ÜîZ(26), C(3)‚ÜîX(24), E(5)‚ÜîV(22) ‚Üí ƒê√°p √°n: G(7)'
                },
                {
                    'concept_name': 'L·∫∑p L·∫°i & TƒÉng T·∫ßn Su·∫•t (Repetition with Increasing Frequency)',
                    'explanation': 'D√£y b·∫Øt ƒë·∫ßu v·ªõi m·ªói ch·ªØ c√°i xu·∫•t hi·ªán s·ªë l·∫ßn kh√°c nhau theo quy lu·∫≠t. V√≠ d·ª•: A xu·∫•t hi·ªán 1 l·∫ßn, B xu·∫•t hi·ªán 2 l·∫ßn, C xu·∫•t hi·ªán 3 l·∫ßn, v.v.',
                    'example': 'A, B, B, C, C, C, D, D, D, D, ? ‚Üí T·∫ßn su·∫•t tƒÉng ‚Üí ƒê√°p √°n: E (E xu·∫•t hi·ªán 5 l·∫ßn, nh∆∞ng c√¢u h·ªèi ch·ªâ h·ªèi ch·ªØ ti·∫øp theo n√™n l√† E)'
                }
            ],
            'step_by_step_method': [
                'B∆∞·ªõc 1: Ghi l·∫°i v·ªã tr√≠ c·ªßa m·ªói ch·ªØ c√°i trong b·∫£ng (A=1, B=2...Z=26)',
                'B∆∞·ªõc 2: T√≠nh kho·∫£ng c√°ch/hi·ªáu s·ªë gi·ªØa c√°c v·ªã tr√≠ li√™n ti·∫øp',
                'B∆∞·ªõc 3: Ph√¢n t√≠ch quy lu·∫≠t: hi·ªáu s·ªë c√≥ ƒë·ªÅu kh√¥ng, hay tƒÉng/gi·∫£m, hay l·∫∑p l·∫°i?',
                'B∆∞·ªõc 4: √Åp d·ª•ng quy lu·∫≠t ƒë·ªÉ t√¨m ch·ªØ c√°i ti·∫øp theo (l∆∞u √Ω: quay v√≤ng khi v∆∞·ª£t Z ho·∫∑c d∆∞·ªõi A)'
            ],
            'common_mistakes': [
                'L·ªói 1: Qu√™n r·∫±ng Z+1 quay v·ªÅ A. N·∫øu t√¨m ƒë∆∞·ª£c ch·ªØ s·ªë 27, ph·∫£i convert th√†nh A (27 mod 26 = 1)',
                'L·ªói 2: Nh·∫ßm l·∫´n v·ªã tr√≠ ch·ªØ c√°i trong d√£y v·ªõi v·ªã tr√≠ trong b·∫£ng. V√≠ d·ª•: ch·ªØ c√°i th·ª© 3 trong d√£y kh√¥ng ph·∫£i C',
                'L·ªói 3: Ch·ªâ t√¨m quy lu·∫≠t tuy·∫øn t√≠nh m√† b·ªè qua c√°c pattern ƒë·∫∑c bi·ªát nh∆∞ n∆∞·ªõc mu·ªëi hay l·∫∑p l·∫°i',
                'L·ªói 4: T√≠nh nh·∫ßm kho·∫£ng c√°ch. V√≠ d·ª•: t·ª´ A(1) ƒë·∫øn D(4) l√† +3, kh√¥ng ph·∫£i +4'
            ],
            'tips_for_accuracy': [
                'M·∫πo 1: Lu√¥n vi·∫øt ra v·ªã tr√≠ s·ªë c·ªßa m·ªói ch·ªØ c√°i (A=1...Z=26). D√πng gi·∫•y nh√°p, kh√¥ng c·∫ßn nh·∫©m t√≠nh',
                'M·∫πo 2: Ki·ªÉm tra 3 hi·ªáu s·ªë ƒë·∫ßu ti√™n. N·∫øu ch√∫ng b·∫±ng nhau, r·∫•t c√≥ th·ªÉ l√† c·∫•p s·ªë c·ªông',
                'M·∫πo 3: N·∫øu kh√¥ng t√¨m ƒë∆∞·ª£c quy lu·∫≠t tuy·∫øn t√≠nh, nh√¨n to√†n c·∫£nh d√£y ƒë·ªÉ ph√°t hi·ªán c√°c pattern ƒë·∫∑c bi·ªát',
                'M·∫πo 4: N·∫øu d√£y ng·∫Øn (3-4 ch·ªØ), h√£y th·ª≠ t·∫•t c·∫£ c√°c pattern c∆° b·∫£n tr∆∞·ªõc khi b·ªè cu·ªôc'
            ],
            'tips_for_speed': [
                'M·∫πo t·ªëc ƒë·ªô 1: D√πng c√°c ch·ªØ c√°i ƒë√°nh d·∫•u (a, b, c) ho·∫∑c v·∫Ω m≈©i t√™n ƒë·ªÉ theo d√µi quy lu·∫≠t nhanh h∆°n',
                'M·∫πo t·ªëc ƒë·ªô 2: N·∫øu hi·ªáu s·ªë c·ªông d·ªìn (1, 2, 3, 4...), nh·∫≠n di·ªán ngay, kh√¥ng c·∫ßn t√≠nh th√™m'
            ],
            'practice_drills': [
                'B√†i t·∫≠p 1: Th·ª±c h√†nh t√≠nh v·ªã tr√≠ 26 ch·ªØ c√°i m·ªôt c√°ch nhanh. L·∫≠p b·∫£ng A=1...Z=26 ƒë·ªÉ ghi nh·ªõ',
                'B√†i t·∫≠p 2: T√¨m quy lu·∫≠t cho 10 d√£y ch·ªØ c√°i kh√°c nhau, m·ªói d√£y 5-7 ch·ªØ',
                'B√†i t·∫≠p 3: Ph√¢n lo·∫°i c√°c d√£y theo pattern (tuy·∫øn t√≠nh, n∆∞·ªõc mu·ªëi, l·∫∑p l·∫°i)',
                'B√†i t·∫≠p 4: Luy·ªán t·∫≠p gi·∫£i 5 b√†i Letter Sequence d∆∞·ªõi √°p l·ª±c th·ªùi gian (30-45 gi√¢y/b√†i)'
            ],
            'key_formulas': [
                'C√¥ng th·ª©c v·ªã tr√≠: N·∫øu hi·ªáu s·ªë l√† d, ch·ªØ c√°i ti·∫øp theo = v·ªã tr√≠ hi·ªán t·∫°i + d',
                'Quay v√≤ng: N·∫øu k·∫øt qu·∫£ > 26, tr·ª´ 26. N·∫øu < 1, c·ªông 26',
                'C·∫•p s·ªë c·ªông: V·ªã tr√≠ = a + (n-1)d, v·ªõi a = v·ªã tr√≠ ƒë·∫ßu, d = hi·ªáu s·ªë, n = v·ªã tr√≠ c·∫ßn t√¨m'
            ]
        },
        'Mixture Problems': {
            'theory': '''L√ù THUY·∫æT ƒê·∫¶Y ƒê·ª¶ V·ªÄ MIXTURE PROBLEMS (B√†i To√°n H·ªón H·ª£p)

1. ƒê·ªäNH NGHƒ®A:
Mixture Problems l√† d·∫°ng b√†i to√°n y√™u c·∫ßu t√≠nh to√°n c√°c thu·ªôc t√≠nh (n·ªìng ƒë·ªô, gi√° tr·ªã, t·ª∑ l·ªá) c·ªßa m·ªôt h·ªón h·ª£p ƒë∆∞·ª£c t·∫°o b·∫±ng c√°ch k·∫øt h·ª£p hai ho·∫∑c nhi·ªÅu th√†nh ph·∫ßn kh√°c nhau. Ch√¨a kh√≥a l√† theo d√µi m·ªôt ƒë·∫°i l∆∞·ª£ng c·ª• th·ªÉ (ch·∫•t tan, th√†nh ph·∫ßn nguy√™n ch·∫•t) qua qu√° tr√¨nh pha tr·ªôn.

2. C√ÅC C√îNG TH·ª®C CH√çNH:
- N·ªìng ƒë·ªô (%) = (L∆∞·ª£ng ch·∫•t tan / T·ªïng l∆∞·ª£ng dung d·ªãch) √ó 100
- L∆∞·ª£ng ch·∫•t tan = N·ªìng ƒë·ªô √ó T·ªïng l∆∞·ª£ng / 100
- Ph∆∞∆°ng tr√¨nh c√¢n b·∫±ng: C‚ÇÅV‚ÇÅ + C‚ÇÇV‚ÇÇ = C_final √ó (V‚ÇÅ + V‚ÇÇ)

3. C√ÅCH √ÅP D·ª§NG:
B∆∞·ªõc 1: Ph√¢n t√≠ch v√† t√≥m t·∫Øt ƒë·ªÅ b√†i b·∫±ng b·∫£ng (T√™n dung d·ªãch, Kh·ªëi l∆∞·ª£ng, N·ªìng ƒë·ªô %, L∆∞·ª£ng ch·∫•t tan)
B∆∞·ªõc 2: X√°c ƒë·ªãnh ƒë·∫°i l∆∞·ª£ng c·∫ßn t√¨m v√† ƒë·∫∑t ·∫©n s·ªë x
B∆∞·ªõc 3: L·∫≠p ph∆∞∆°ng tr√¨nh d·ª±a tr√™n c√¢n b·∫±ng ch·∫•t tan ho·∫∑c b·∫•t bi·∫øn
B∆∞·ªõc 4: Gi·∫£i ph∆∞∆°ng tr√¨nh v√† ki·ªÉm tra t√≠nh h·ª£p l√Ω

4. V√ç D·ª§ MINH H·ªåA:
Tr·ªôn 30L dung d·ªãch mu·ªëi 10% v·ªõi 20L dung d·ªãch mu·ªëi 25%. N·ªìng ƒë·ªô mu·ªëi m·ªõi?
- Dung d·ªãch 1: 30L √ó 10% = 3L mu·ªëi
- Dung d·ªãch 2: 20L √ó 25% = 5L mu·ªëi
- T·ªïng mu·ªëi: 3 + 5 = 8L, T·ªïng th·ªÉ t√≠ch: 50L
- N·ªìng ƒë·ªô m·ªõi = 8/50 √ó 100 = 16%

5. L∆ØU √ù QUAN TR·ªåNG:
- Ch·∫•t nguy√™n ch·∫•t (axit, v√†ng) = 100% n·ªìng ƒë·ªô
- N∆∞·ªõc/dung m√¥i nguy√™n ch·∫•t = 0% n·ªìng ƒë·ªô
- Khi bay h∆°i n∆∞·ªõc: l∆∞·ª£ng ch·∫•t tan kh√¥ng ƒë·ªïi, nh∆∞ng t·ªïng dung d·ªãch gi·∫£m
- Lu√¥n ki·ªÉm tra: k·∫øt qu·∫£ ph·∫£i n·∫±m gi·ªØa n·ªìng ƒë·ªô c·ªßa 2 th√†nh ph·∫ßn ban ƒë·∫ßu'''
        },
        'Number Properties': {
            'theory': '''L√ù THUY·∫æT CHI TI·∫æT V·ªÄ NUMBER PROPERTIES (T√≠nh Ch·∫•t S·ªë)

1. ƒê·ªäNH NGHƒ®A:
Number Properties l√† c√°c ƒë·∫∑c t√≠nh c∆° b·∫£n c·ªßa s·ªë (ch·∫µn/l·∫ª, nguy√™n t·ªë, chia h·∫øt, v.v.) ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ gi·∫£i c√°c b√†i to√°n logic v√† ƒë·∫°i s·ªë tr√™n GMAT.

2. C√ÅC KH√ÅI NI·ªÜM CH√çNH:
- S·ªê CH·∫¥N/L·∫∫: Ch·∫µn chia h·∫øt cho 2, l·∫ª kh√¥ng. Ch·∫µn+Ch·∫µn=Ch·∫µn, L·∫ª+L·∫ª=Ch·∫µn, Ch·∫µn+L·∫ª=L·∫ª
- S·ªê NGUY√äN T·ªê: Ch·ªâ chia h·∫øt cho 1 v√† ch√≠nh n√≥ (2, 3, 5, 7, 11, 13, 17, 19, 23, 29...)
- CHIA H·∫æT: a chia h·∫øt cho b n·∫øu a = b√ók (k l√† s·ªë nguy√™n)
- ∆Ø·ªöC CHUNG & B·ªòI CHUNG: GCD (∆∞·ªõc l·ªõn nh·∫•t), LCM (b·ªôi nh·ªè nh·∫•t)

3. C√ÅCH √ÅP D·ª§NG:
B∆∞·ªõc 1: X√°c ƒë·ªãnh lo·∫°i b√†i to√°n (ch·∫µn/l·∫ª, chia h·∫øt, nguy√™n t·ªë, hay ph√¢n t√≠ch th·ª´a s·ªë)
B∆∞·ªõc 2: Li·ªát k√™ c√°c t√≠nh ch·∫•t c·ªßa c√°c s·ªë trong b√†i
B∆∞·ªõc 3: √Åp d·ª•ng quy t·∫Øc ph√π h·ª£p
B∆∞·ªõc 4: Ki·ªÉm tra b·∫±ng v√≠ d·ª• c·ª• th·ªÉ

4. V√ç D·ª§:
N·∫øu x l√† s·ªë ch·∫µn v√† y l√† s·ªë l·∫ª, x+y l√†?
‚Üí Ch·∫µn + L·∫ª = L·∫ª'''
        }
    }

def generate_study_guide(questions: List[Dict[str, Any]], user_answers: Dict[str, str]) -> Dict[str, Any]:
    """
    T·∫°o t√†i li·ªáu √¥n t·∫≠p chi ti·∫øt d·ª±a tr√™n c√°c c√¢u h·ªèi trong b√†i thi
    
    Args:
        questions: Danh s√°ch c√°c c√¢u h·ªèi trong b√†i thi
        user_answers: Dict ch·ª©a c√¢u tr·∫£ l·ªùi c·ªßa user {q_0: 'A. ...', q_1: 'B. ...'}
    
    Returns:
        Dict ch·ª©a n·ªôi dung √¥n t·∫≠p theo t·ª´ng topic
    """
    model = _get_study_model()
    if not model:
        return {
            "error": "Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn AI. Vui l√≤ng ki·ªÉm tra API key.",
            "topics": []
        }
    
    # Ph√¢n t√≠ch c√¢u sai v√† ƒë√∫ng theo topic - GI·ªÆ TO√ÄN B·ªò TH√îNG TIN
    topic_analysis = {}
    
    for idx, q in enumerate(questions):
        topic = q.get('topic', 'General')
        qtype = q.get('type', 'general')
        user_choice = user_answers.get(f"q_{idx}")
        correct_answer = q.get('correct_answer', '')
        
        is_correct = False
        if user_choice and correct_answer:
            if user_choice.split('.')[0] == correct_answer.split('.')[0]:
                is_correct = True
        
        if topic not in topic_analysis:
            topic_analysis[topic] = {
                'type': qtype,
                'total': 0,
                'correct': 0,
                'wrong': 0,
                'questions': [],
                'wrong_questions': []  # T√°ch ri√™ng c√¢u sai ƒë·ªÉ ∆∞u ti√™n ph√¢n t√≠ch
            }
        
        topic_analysis[topic]['total'] += 1
        if is_correct:
            topic_analysis[topic]['correct'] += 1
        else:
            topic_analysis[topic]['wrong'] += 1
        
        # L∆∞u TO√ÄN B·ªò th√¥ng tin c√¢u h·ªèi (kh√¥ng c·∫Øt ng·∫Øn)
        question_data = {
            'question': q.get('question', ''),
            'options': q.get('options', []),
            'user_choice': user_choice,
            'correct_answer': correct_answer,
            'explanation': q.get('explanation', ''),
            'step_by_step_thinking': q.get('step_by_step_thinking', ''),
            'is_correct': is_correct
        }
        
        topic_analysis[topic]['questions'].append(question_data)
        if not is_correct:
            topic_analysis[topic]['wrong_questions'].append(question_data)
    
    # X·ª¨ L√ù T·ª™NG CH·ª¶ ƒê·ªÄ M·ªòT - ∆ØU TI√äN CH·ª¶ ƒê·ªÄ C√ì NHI·ªÄU C√ÇU SAI
    sorted_topics = sorted(
        topic_analysis.items(),
        key=lambda x: (x[1]['wrong'], -x[1]['total']),  # S·∫Øp theo s·ªë c√¢u sai (nhi·ªÅu nh·∫•t tr∆∞·ªõc)
        reverse=True
    )
    
    all_topics_guides = []
    
    for topic_name, data in sorted_topics:
        accuracy = (data['correct'] / data['total'] * 100) if data['total'] > 0 else 0
        wrong_count = data['wrong']
        
        # Ch·ªâ ph√¢n t√≠ch chi ti·∫øt n·∫øu c√≥ c√¢u sai HO·∫∂C accuracy < 100%
        if wrong_count == 0 and accuracy == 100:
            # Topic ho√†n h·∫£o - t·∫°o guide ƒë∆°n gi·∫£n
            all_topics_guides.append({
                'topic': topic_name,
                'accuracy': round(accuracy, 0),
                'importance': 'low',
                'priority_level': 3,
                'key_concepts': [f"B·∫°n ƒë√£ n·∫Øm v·ªØng {topic_name}!"],
                'common_mistakes': [],
                'study_tips': [f"Ti·∫øp t·ª•c duy tr√¨ hi·ªÉu bi·∫øt v·ªÅ {topic_name}"],
                'practice_approach': f"B·∫°n kh√¥ng c√≥ l·ªói n√†o ·ªü {topic_name}. Ti·∫øp t·ª•c!",
                'formulas_or_rules': [],
                'practice_drills': [],
                'time_management_tip': 'Duy tr√¨ t·ªëc ƒë·ªô hi·ªán t·∫°i',
                'stats': {
                    'total': data['total'],
                    'correct': data['correct'],
                    'wrong': data['wrong']
                }
            })
            continue
    
        # T·∫†O PROMPT CHI TI·∫æT CHO T·ª™NG TOPIC - BAO G·ªíM C√ÇU H·ªéI SAI ƒê·∫¶Y ƒê·ª¶
        importance = 'high' if accuracy < 60 else ('medium' if accuracy < 80 else 'low')
        priority = 1 if importance == 'high' else (2 if importance == 'medium' else 3)
        
        # Chu·∫©n b·ªã chi ti·∫øt c√°c c√¢u SAI ƒë·ªÉ ph√¢n t√≠ch
        wrong_details = []
        for q in data['wrong_questions']:
            wrong_details.append({
                'question': q['question'],
                'options': q['options'],
                'user_choice': q['user_choice'],
                'correct_answer': q['correct_answer'],
                'explanation': q['explanation'],
                'step_by_step': q['step_by_step_thinking']
            })
        
        # Prompt chi ti·∫øt cho T·ª™NG topic
        topic_prompt = f"""
B·∫°n l√† gi√°o vi√™n GMAT chuy√™n nghi·ªáp. Ph√¢n t√≠ch chi ti·∫øt ch·ªß ƒë·ªÅ "{topic_name}" cho h·ªçc sinh.

TH·ªêNG K√ä:
- T·ªïng s·ªë c√¢u: {data['total']}
- S·ªë c√¢u ƒë√∫ng: {data['correct']}
- S·ªë c√¢u sai: {wrong_count}
- ƒê·ªô ch√≠nh x√°c: {accuracy:.0f}%

C√ÅC C√ÇU H·ªéI H·ªåC SINH TR·∫¢ L·ªúI SAI (c·∫ßn ph√¢n t√≠ch chi ti·∫øt):
{json.dumps(wrong_details, ensure_ascii=False, indent=2)}

NHI·ªÜM V·ª§:
1. **L√Ω thuy·∫øt chi ti·∫øt ƒë·∫ßy ƒë·ªß**: Gi·∫£i th√≠ch TO√ÄN B·ªò ki·∫øn th·ª©c v·ªÅ {topic_name}
2. **Ph√¢n t√≠ch b√†i l√†m**: ƒêi qua T·ª™NG c√¢u sai v·ªõi chi ti·∫øt c·ª• th·ªÉ
3. **L·ªói ph·ªï bi·∫øn**: Li·ªát k√™ ƒë·∫ßy ƒë·ªß c√°c l·ªói th∆∞·ªùng g·∫∑p
4. **M·∫πo th·ª±c chi·∫øn**: C·ª• th·ªÉ, √°p d·ª•ng ngay ƒë∆∞·ª£c

OUTPUT (JSON format):
{{
    "theory": "L√ù THUY·∫æT ƒê·∫¶Y ƒê·ª¶ v·ªÅ {topic_name}:\\n\\n1. ƒê·ªäNH NGHƒ®A: Gi·∫£i th√≠ch r√µ r√†ng kh√°i ni·ªám c∆° b·∫£n (3-4 c√¢u)\\n\\n2. C√îNG TH·ª®C/QUY T·∫ÆC CH√çNH: Li·ªát k√™ t·∫•t c·∫£ c√¥ng th·ª©c quan tr·ªçng v·ªõi gi·∫£i th√≠ch\\n\\n3. C√ÅCH √ÅP D·ª§NG: H∆∞·ªõng d·∫´n t·ª´ng b∆∞·ªõc c√°ch s·ª≠ d·ª•ng c√¥ng th·ª©c/quy t·∫Øc (4-5 b∆∞·ªõc chi ti·∫øt)\\n\\n4. V√ç D·ª§ MINH H·ªåA: √çt nh·∫•t 1 v√≠ d·ª• c·ª• th·ªÉ v·ªõi l·ªùi gi·∫£i chi ti·∫øt\\n\\n5. L∆ØU √ù QUAN TR·ªåNG: C√°c ƒëi·ªÉm d·ªÖ nh·∫ßm l·∫´n c·∫ßn ch√∫ √Ω",
    
    "detailed_concepts": [
        {{
            "concept_name": "Kh√°i ni·ªám/K·ªπ thu·∫≠t 1",
            "explanation": "Gi·∫£i th√≠ch chi ti·∫øt 3-4 c√¢u v·ªõi v√≠ d·ª• c·ª• th·ªÉ",
            "example": "V√≠ d·ª• minh h·ªça r√µ r√†ng"
        }},
        {{
            "concept_name": "Kh√°i ni·ªám/K·ªπ thu·∫≠t 2",
            "explanation": "Gi·∫£i th√≠ch chi ti·∫øt 3-4 c√¢u v·ªõi v√≠ d·ª• c·ª• th·ªÉ",
            "example": "V√≠ d·ª• minh h·ªça r√µ r√†ng"
        }},
        {{
            "concept_name": "Kh√°i ni·ªám/K·ªπ thu·∫≠t 3",
            "explanation": "Gi·∫£i th√≠ch chi ti·∫øt 3-4 c√¢u v·ªõi v√≠ d·ª• c·ª• th·ªÉ",
            "example": "V√≠ d·ª• minh h·ªça r√µ r√†ng"
        }}
    ],
    
    "step_by_step_method": [
        "B∆∞·ªõc 1: M√¥ t·∫£ chi ti·∫øt c√°ch th·ª±c hi·ªán b∆∞·ªõc n√†y",
        "B∆∞·ªõc 2: M√¥ t·∫£ chi ti·∫øt c√°ch th·ª±c hi·ªán b∆∞·ªõc n√†y",
        "B∆∞·ªõc 3: M√¥ t·∫£ chi ti·∫øt c√°ch th·ª±c hi·ªán b∆∞·ªõc n√†y",
        "B∆∞·ªõc 4: M√¥ t·∫£ chi ti·∫øt c√°ch th·ª±c hi·ªán b∆∞·ªõc n√†y"
    ],
    
    "mistake_analysis": [
        {{
            "question_summary": "T√≥m t·∫Øt ng·∫Øn c√¢u h·ªèi",
            "user_mistake": "H·ªçc sinh ƒë√£ ch·ªçn... v√¨ hi·ªÉu sai r·∫±ng...",
            "why_wrong": "L√Ω do t·∫°i sao sai (chi ti·∫øt 2-3 c√¢u)",
            "correct_approach": "C√°ch suy lu·∫≠n ƒë√∫ng t·ª´ng b∆∞·ªõc v·ªõi gi·∫£i th√≠ch c·ª• th·ªÉ"
        }}
    ],
    
    "common_mistakes": [
        "L·ªói 1: M√¥ t·∫£ chi ti·∫øt l·ªói + C√°ch nh·∫≠n bi·∫øt + C√°ch tr√°nh c·ª• th·ªÉ",
        "L·ªói 2: M√¥ t·∫£ chi ti·∫øt l·ªói + C√°ch nh·∫≠n bi·∫øt + C√°ch tr√°nh c·ª• th·ªÉ",
        "L·ªói 3: M√¥ t·∫£ chi ti·∫øt l·ªói + C√°ch nh·∫≠n bi·∫øt + C√°ch tr√°nh c·ª• th·ªÉ",
        "L·ªói 4: M√¥ t·∫£ chi ti·∫øt l·ªói + C√°ch nh·∫≠n bi·∫øt + C√°ch tr√°nh c·ª• th·ªÉ"
    ],
    
    "tips_for_accuracy": [
        "M·∫πo 1: K·ªπ thu·∫≠t c·ª• th·ªÉ v·ªõi v√≠ d·ª• √°p d·ª•ng (2-3 c√¢u)",
        "M·∫πo 2: K·ªπ thu·∫≠t c·ª• th·ªÉ v·ªõi v√≠ d·ª• √°p d·ª•ng (2-3 c√¢u)",
        "M·∫πo 3: K·ªπ thu·∫≠t c·ª• th·ªÉ v·ªõi v√≠ d·ª• √°p d·ª•ng (2-3 c√¢u)",
        "M·∫πo 4: K·ªπ thu·∫≠t c·ª• th·ªÉ v·ªõi v√≠ d·ª• √°p d·ª•ng (2-3 c√¢u)"
    ],
    
    "tips_for_speed": [
        "M·∫πo tƒÉng t·ªëc 1: K·ªπ thu·∫≠t r√∫t g·ªçn c·ª• th·ªÉ (2 c√¢u)",
        "M·∫πo tƒÉng t·ªëc 2: K·ªπ thu·∫≠t r√∫t g·ªçn c·ª• th·ªÉ (2 c√¢u)",
        "M·∫πo tƒÉng t·ªëc 3: K·ªπ thu·∫≠t r√∫t g·ªçn c·ª• th·ªÉ (2 c√¢u)"
    ],
    
    "practice_drills": [
        "B√†i t·∫≠p 1: M√¥ t·∫£ b√†i t·∫≠p ng·∫Øn ƒë·ªÉ r√®n k·ªπ nƒÉng c·ª• th·ªÉ",
        "B√†i t·∫≠p 2: M√¥ t·∫£ b√†i t·∫≠p ng·∫Øn ƒë·ªÉ r√®n k·ªπ nƒÉng c·ª• th·ªÉ",
        "B√†i t·∫≠p 3: M√¥ t·∫£ b√†i t·∫≠p ng·∫Øn ƒë·ªÉ r√®n k·ªπ nƒÉng c·ª• th·ªÉ",
        "B√†i t·∫≠p 4: M√¥ t·∫£ b√†i t·∫≠p ng·∫Øn ƒë·ªÉ r√®n k·ªπ nƒÉng c·ª• th·ªÉ"
    ],
    
    "key_formulas": [
        "C√¥ng th·ª©c 1: Di·ªÖn gi·∫£i + Khi n√†o d√πng",
        "C√¥ng th·ª©c 2: Di·ªÖn gi·∫£i + Khi n√†o d√πng",
        "C√¥ng th·ª©c 3: Di·ªÖn gi·∫£i + Khi n√†o d√πng"
    ]
}}

Y√äU C·∫¶U QUAN TR·ªåNG:
- Ph·∫ßn "theory" PH·∫¢I c√≥ c·∫•u tr√∫c 5 ph·∫ßn nh∆∞ m√¥ t·∫£ (ƒê·ªäNH NGHƒ®A, C√îNG TH·ª®C, C√ÅCH √ÅP D·ª§NG, V√ç D·ª§, L∆ØU √ù)
- Ph·∫ßn "detailed_concepts" PH·∫¢I c√≥ √≠t nh·∫•t 3 kh√°i ni·ªám v·ªõi v√≠ d·ª• c·ª• th·ªÉ
- Ph·∫ßn "step_by_step_method" PH·∫¢I c√≥ √≠t nh·∫•t 4 b∆∞·ªõc chi ti·∫øt
- Ph√¢n t√≠ch C·ª§ TH·ªÇ d·ª±a tr√™n c√°c c√¢u sai ƒë∆∞·ª£c cung c·∫•p
- M·ªñI M·ª§C ph·∫£i d√†i, chi ti·∫øt, C√ì V√ç D·ª§
- Kh√¥ng vi·∫øt chung chung - ph·∫£i c·ª• th·ªÉ, √°p d·ª•ng ƒë∆∞·ª£c ngay
- Tr·∫£ v·ªÅ JSON thu·∫ßn, kh√¥ng c√≥ markdown
"""

        try:
            # G·ªçi API cho T·ª™NG topic
            response = model.models.generate_content(
                model='gemini-2.5-pro',
                contents=topic_prompt,
                config={
                    'temperature': 0.3,  # Gi·∫£m ƒë·ªÉ t·∫≠p trung, c·ª• th·ªÉ
                    'max_output_tokens': 8192,  # ƒê·ªß cho 1 topic chi ti·∫øt
                    'top_p': 0.9,
                    'top_k': 30,
                    'response_mime_type': 'application/json'
                }
            )
            
            text = response.text if hasattr(response, 'text') else str(response)
            print(f"‚úÖ Topic '{topic_name}': Generated {len(text)} chars")
            
            # Parse JSON response
            text = text.replace('```json', '').replace('```', '').strip()
            
            # Fix multiple closing braces (common AI error)
            # Replace }}} with }} at end of JSON
            text = re.sub(r'\}\}\}+\s*$', '}}', text)
            # Replace }]}} with }]} 
            text = re.sub(r'\}\]\}\}+', '}]}', text)
            
            # Validate JSON before parsing
            if not text or text == '{}':
                raise ValueError("Empty JSON response from API")
            
            topic_guide = json.loads(text)
            
            # Validate required fields
            required_fields = ['theory', 'detailed_concepts', 'step_by_step_method', 'common_mistakes', 'tips_for_accuracy']
            missing_fields = [f for f in required_fields if f not in topic_guide or not topic_guide[f]]
            if missing_fields:
                print(f"‚ö†Ô∏è Missing fields in response for '{topic_name}': {missing_fields}")
                raise ValueError(f"Missing required fields: {missing_fields}")
            
            # Th√™m metadata
            topic_guide['topic'] = topic_name
            topic_guide['accuracy'] = round(accuracy, 0)
            topic_guide['importance'] = importance
            topic_guide['priority_level'] = priority
            topic_guide['stats'] = {
                'total': data['total'],
                'correct': data['correct'],
                'wrong': data['wrong']
            }
            
            all_topics_guides.append(topic_guide)
            
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói ph√¢n t√≠ch topic '{topic_name}': {e}")
            import traceback
            traceback.print_exc()
            
            # Th·ª≠ l·∫•y t·ª´ knowledge base, n·∫øu kh√¥ng c√≥ th√¨ t·∫°o fallback
            knowledge_base = _get_topic_knowledge_base()
            if topic_name in knowledge_base:
                kb_data = knowledge_base[topic_name]
                all_topics_guides.append({
                    'topic': topic_name,
                    'accuracy': round(accuracy, 0),
                    'importance': importance,
                    'priority_level': priority,
                    'theory': kb_data['theory'],
                    'detailed_concepts': kb_data.get('detailed_concepts', []),
                    'step_by_step_method': kb_data.get('step_by_step_method', []),
                    'mistake_analysis': [],
                    'common_mistakes': kb_data.get('common_mistakes', [f"B·∫°n sai {wrong_count} c√¢u ·ªü {topic_name}. C·∫ßn √¥n l·∫°i l√Ω thuy·∫øt."]),
                    'tips_for_accuracy': kb_data.get('tips_for_accuracy', []),
                    'tips_for_speed': kb_data.get('tips_for_speed', []),
                    'practice_drills': kb_data.get('practice_drills', []),
                    'key_formulas': kb_data.get('key_formulas', []),
                    'stats': {
                        'total': data['total'],
                        'correct': data['correct'],
                        'wrong': data['wrong']
                    }
                })
            else:
                # Fallback chung chung cho topic kh√¥ng trong knowledge base
                all_topics_guides.append({
                    'topic': topic_name,
                    'accuracy': round(accuracy, 0),
                    'importance': importance,
                    'priority_level': priority,
                    'theory': f"C·∫ßn √¥n t·∫≠p l·∫°i ki·∫øn th·ª©c c∆° b·∫£n v·ªÅ {topic_name}. H√£y xem l·∫°i ƒë·ªãnh nghƒ©a, c√¥ng th·ª©c v√† c√°ch √°p d·ª•ng trong c√°c b√†i to√°n. Luy·ªán t·∫≠p th√™m ƒë·ªÉ n·∫Øm v·ªØng.",
                    'detailed_concepts': [
                        {'concept_name': f'Kh√°i ni·ªám c∆° b·∫£n {topic_name}', 'explanation': 'C·∫ßn √¥n l·∫°i t·ª´ ƒë·∫ßu', 'example': 'Xem s√°ch gi√°o khoa'}
                    ],
                    'step_by_step_method': [
                        'B∆∞·ªõc 1: ƒê·ªçc k·ªπ ƒë·ªÅ b√†i',
                        'B∆∞·ªõc 2: X√°c ƒë·ªãnh d·∫°ng b√†i',
                        'B∆∞·ªõc 3: √Åp d·ª•ng c√¥ng th·ª©c',
                        'B∆∞·ªõc 4: Ki·ªÉm tra k·∫øt qu·∫£'
                    ],
                    'mistake_analysis': [],
                    'common_mistakes': [f"B·∫°n sai {wrong_count} c√¢u ·ªü {topic_name}. C·∫ßn √¥n l·∫°i l√Ω thuy·∫øt."],
                    'tips_for_accuracy': [f"√în l·∫°i l√Ω thuy·∫øt {topic_name} t·ª´ s√°ch c∆° b·∫£n"],
                    'tips_for_speed': ["Luy·ªán t·∫≠p th√™m ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô"],
                    'practice_drills': [f"L√†m th√™m {max(5, wrong_count * 2)} b√†i t·∫≠p v·ªÅ {topic_name}"],
                    'key_formulas': ["Xem l·∫°i c√¥ng th·ª©c c∆° b·∫£n"],
                    'stats': {
                        'total': data['total'],
                        'correct': data['correct'],
                        'wrong': data['wrong']
                    }
                })
    
    # T·∫°o t·ªïng quan
    total_correct = sum(d['correct'] for d in topic_analysis.values())
    total_questions = sum(d['total'] for d in topic_analysis.values())
    total_wrong = sum(d['wrong'] for d in topic_analysis.values())
    overall_accuracy = (total_correct / total_questions * 100) if total_questions > 0 else 0
    
    return {
        'overall_summary': f"K·∫øt qu·∫£: {total_correct}/{total_questions} ƒë√∫ng ({overall_accuracy:.0f}%). B·∫°n c·∫ßn t·∫≠p trung √¥n t·∫≠p {total_wrong} c√¢u sai, ƒë·∫∑c bi·ªát c√°c ch·ªß ƒë·ªÅ: {', '.join([t['topic'] for t in all_topics_guides[:3] if t.get('importance') in ['high', 'medium']])}.",
        'topics': all_topics_guides
    }


def _create_fallback_study_guide(topic_analysis: Dict[str, Any]) -> Dict[str, Any]:
    """
    T·∫°o study guide ƒë∆°n gi·∫£n khi AI parse JSON fail ho·∫∑c API error
    """
    print(f"üìä Creating fallback study guide...")
    topics = []
    
    for topic_name, data in sorted(
        topic_analysis.items(),
        key=lambda x: x[1]['wrong'],
        reverse=True
    ):
        accuracy = (data['correct'] / data['total'] * 100) if data['total'] > 0 else 0
        importance = 'high' if accuracy < 60 else ('medium' if accuracy < 80 else 'low')
        
        topic_guide = {
            'topic': topic_name,
            'accuracy': round(accuracy, 0),
            'importance': importance,
            'priority_level': 1 if importance == 'high' else (2 if importance == 'medium' else 3),
            'theory': f"√în t·∫≠p l·∫°i {topic_name} t·ª´ c∆° b·∫£n. B·∫°n sai {data['wrong']} c√¢u, c·∫ßn xem l·∫°i l√Ω thuy·∫øt, c√¥ng th·ª©c v√† c√°ch √°p d·ª•ng. L√†m th√™m b√†i t·∫≠p ƒë·ªÉ c·ªßng c·ªë.",
            'detailed_concepts': [
                {'concept_name': f'Kh√°i ni·ªám c∆° b·∫£n {topic_name}', 'explanation': f'C·∫ßn n·∫Øm v·ªØng ƒë·ªãnh nghƒ©a v√† ·ª©ng d·ª•ng c·ªßa {topic_name}', 'example': 'Xem s√°ch gi√°o khoa v√† l√†m b√†i t·∫≠p m·∫´u'},
                {'concept_name': '·ª®ng d·ª•ng th·ª±c t·∫ø', 'explanation': f'√Åp d·ª•ng {topic_name} trong c√°c b√†i to√°n GMAT', 'example': 'Luy·ªán t·∫≠p c√°c d·∫°ng b√†i th∆∞·ªùng g·∫∑p'},
                {'concept_name': 'Li√™n k·∫øt ki·∫øn th·ª©c', 'explanation': f'K·∫øt h·ª£p {topic_name} v·ªõi c√°c ch·ªß ƒë·ªÅ kh√°c', 'example': 'Hi·ªÉu m·ªëi quan h·ªá gi·ªØa c√°c topic'}
            ],
            'step_by_step_method': [
                'B∆∞·ªõc 1: ƒê·ªçc ƒë·ªÅ k·ªπ l∆∞·ª°ng v√† x√°c ƒë·ªãnh y√™u c·∫ßu',
                'B∆∞·ªõc 2: X√°c ƒë·ªãnh d·∫°ng b√†i v√† ph∆∞∆°ng ph√°p gi·∫£i',
                'B∆∞·ªõc 3: √Åp d·ª•ng c√¥ng th·ª©c/quy t·∫Øc ph√π h·ª£p',
                'B∆∞·ªõc 4: Ki·ªÉm tra l·∫°i k·∫øt qu·∫£ v√† logic'
            ],
            'mistake_analysis': [],
            'common_mistakes': [
                f"B·∫°n tr·∫£ l·ªùi sai {data['wrong']} c√¢u ({100-accuracy:.0f}% t·ª∑ l·ªá sai)",
                f"C√°c l·ªói ph·ªï bi·∫øn: nh·∫ßm l·∫´n ƒë·ªãnh nghƒ©a, t√≠nh to√°n sai, hi·ªÉu sai ƒë·ªÅ",
                f"C√°ch tr√°nh: ƒë·ªçc k·ªπ ƒë·ªÅ, ki·ªÉm tra l·∫°i, √¥n l·∫°i c√¥ng th·ª©c"
            ],
            'tips_for_accuracy': [
                f"√în t·∫≠p l·∫°i {topic_name} t·ª´ s√°ch c∆° b·∫£n",
                f"L√†m th√™m {max(5, data['wrong'] * 2)} b√†i t·∫≠p th·ª±c h√†nh",
                f"Ghi ch√©p l·∫°i c√°c l·ªói sai v√† c√°ch gi·∫£i quy·∫øt"
            ],
            'tips_for_speed': [
                f"D√†nh {max(1, 30 // len(topic_analysis))} ph√∫t cho m·ªói c√¢u {topic_name}",
                "N·∫øu qu√° kh√≥, b·ªè qua v√† quay l·∫°i sau"
            ],
            'practice_drills': [
                f"L√†m {max(5, data['wrong'] * 2)} b√†i t·∫≠p {topic_name}",
                "L√†m l·∫°i c√°c c√¢u sai ƒë·ªÉ hi·ªÉu r√µ l√Ω do",
                "Tham kh·∫£o l·ªùi gi·∫£i chi ti·∫øt"
            ],
            'key_formulas': [
                f"C√¥ng th·ª©c c∆° b·∫£n {topic_name}: Xem l·∫°i s√°ch gi√°o khoa",
                "Quy t·∫Øc quan tr·ªçng: √în l·∫°i ƒë·ªãnh nghƒ©a"
            ],
            'stats': {
                'total': data['total'],
                'correct': data['correct'],
                'wrong': data['wrong']
            }
        }
        topics.append(topic_guide)
    
    return {
        'overall_summary': f"B·∫°n c·∫ßn √¥n t·∫≠p {sum(d['wrong'] for d in topic_analysis.values())} c√¢u sai. H√£y t·∫≠p trung v√†o c√°c topic c√≥ t·ª∑ l·ªá sai cao. V·ªõi s·ª± ki√™n tr√¨ v√† luy·ªán t·∫≠p th√™m, b·∫°n s·∫Ω c·∫£i thi·ªán ƒëi·ªÉm s·ªë!",
        'topics': topics,
        'recommended_focus': [f"{t['topic']}" for t in topics[:3]],
        'next_steps': f"Ng√†y 1-2: √în l·∫°i l√Ω thuy·∫øt c√°c topic d·ªÖ sai. Ng√†y 3-4: L√†m b√†i t·∫≠p th·ª±c h√†nh. Ng√†y 5-6: L√†m l·∫°i c√°c c√¢u sai. Ng√†y 7: Ki·ªÉm tra to√†n di·ªán.",
        'practice_resources': [
            "S√°ch GMAT ch√≠nh th·ª©c: Luy·ªán t·∫≠p c√°c d·∫°ng b√†i",
            "B√†i t·∫≠p online: L√†m th√™m 50+ b√†i t·∫≠p theo topic"
        ],
        'motivation_message': "H√£y nh·ªõ r·∫±ng m·ªói l·∫ßn sai l√† c∆° h·ªôi ƒë·ªÉ h·ªçc. Ti·∫øp t·ª•c c·ªë g·∫Øng v√† b·∫°n s·∫Ω ƒë·∫°t ƒëi·ªÉm cao!"
    }

def format_study_guide_html(study_data: Dict[str, Any]) -> str:
    """
    Chuy·ªÉn study guide data th√†nh HTML ƒë·∫πp ƒë·ªÉ hi·ªÉn th·ªã trong Streamlit
    """
    if 'error' in study_data:
        return f"<div style='color:red;'>‚ùå {study_data['error']}</div>"
    
    html = "<div style='font-family: system-ui; max-width: 1200px;'>"
    
    # Overall Summary - Improved styling
    summary = study_data.get('overall_summary', '')
    if summary:
        html += f"""
        <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                    color: white; padding: 25px; border-radius: 15px; margin-bottom: 25px;
                    box-shadow: 0 4px 6px rgba(0,0,0,0.1);'>
            <h2 style='margin:0 0 15px 0; font-size: 24px;'>üìä T·ªïng quan k·∫øt qu·∫£</h2>
            <p style='margin:0; font-size: 16px; line-height: 1.8; opacity: 0.95;'>{summary}</p>
        </div>
        """
    
    # Topics with improved design
    topics = study_data.get('topics', [])
    for idx, topic in enumerate(topics, 1):
        importance = topic.get('importance', 'medium')
        color_map = {
            'high': '#dc3545',
            'medium': '#fd7e14',
            'low': '#28a745'
        }
        bg_color_map = {
            'high': '#fff5f5',
            'medium': '#fff8f0',
            'low': '#f0f9f4'
        }
        icon_map = {
            'high': 'üî¥',
            'medium': 'üü°',
            'low': 'üü¢'
        }
        
        color = color_map.get(importance, '#666')
        bg_color = bg_color_map.get(importance, '#f8f9fa')
        icon = icon_map.get(importance, '‚≠ï')
        
        stats = topic.get('stats', {})
        accuracy = (stats.get('correct', 0) / stats.get('total', 1) * 100) if stats.get('total', 1) > 0 else 0
        
        html += f"""
        <div style='border: 2px solid {color}; border-radius: 12px; 
                    padding: 25px; margin-bottom: 25px; background: {bg_color};
                    box-shadow: 0 2px 4px rgba(0,0,0,0.05);'>
            <div style='display: flex; justify-content: space-between; align-items: center; margin-bottom: 15px;'>
                <h3 style='color: {color}; margin: 0; font-size: 20px;'>
                    {icon} {topic['topic']}
                </h3>
                <div style='background: white; padding: 8px 15px; border-radius: 20px; 
                           border: 2px solid {color}; font-weight: bold; color: {color};'>
                    {stats.get('correct', 0)}/{stats.get('total', 0)} ƒë√∫ng ({accuracy:.0f}%)
                </div>
            </div>
        """
        
        # Priority badge
        priority = topic.get('priority_level', 2)
        if priority == 1:
            html += """
            <div style='background: #ff4444; color: white; display: inline-block; 
                       padding: 5px 15px; border-radius: 15px; font-size: 12px; 
                       font-weight: bold; margin-bottom: 15px;'>
                ‚ö° ∆ØU TI√äN CAO
            </div>
            """
        
        # Key Concepts - Improved
        concepts = topic.get('key_concepts', [])
        if concepts:
            html += """
            <div style='background: white; padding: 15px; border-radius: 8px; margin-bottom: 15px;'>
                <h4 style='margin: 0 0 10px 0; color: #495057; font-size: 16px;'>üí° Ki·∫øn th·ª©c c·ªët l√µi</h4>
                <ul style='margin: 0; padding-left: 20px;'>
            """
            for concept in concepts:
                html += f"<li style='margin-bottom: 8px; line-height: 1.6;'>{concept}</li>"
            html += "</ul></div>"
        
        # Common Mistakes - Improved
        mistakes = topic.get('common_mistakes', [])
        if mistakes:
            html += """
            <div style='background: #fff5f5; padding: 15px; border-radius: 8px; 
                       margin-bottom: 15px; border-left: 4px solid #dc3545;'>
                <h4 style='margin: 0 0 10px 0; color: #dc3545; font-size: 16px;'>‚ö†Ô∏è L·ªói th∆∞·ªùng g·∫∑p</h4>
                <ul style='margin: 0; padding-left: 20px;'>
            """
            for mistake in mistakes:
                html += f"<li style='margin-bottom: 8px; line-height: 1.6; color: #721c24;'>{mistake}</li>"
            html += "</ul></div>"
        
        # Study Tips - Improved
        tips = topic.get('study_tips', [])
        if tips:
            html += """
            <div style='background: #f0f9f4; padding: 15px; border-radius: 8px; 
                       margin-bottom: 15px; border-left: 4px solid #28a745;'>
                <h4 style='margin: 0 0 10px 0; color: #28a745; font-size: 16px;'>‚ú® M·∫πo h·ªçc t·∫≠p</h4>
                <ul style='margin: 0; padding-left: 20px;'>
            """
            for tip in tips:
                html += f"<li style='margin-bottom: 8px; line-height: 1.6; color: #155724;'>{tip}</li>"
            html += "</ul></div>"
        
        # Practice Approach - Improved
        approach = topic.get('practice_approach', '')
        if approach:
            html += f"""
            <div style='background: linear-gradient(to right, #e3f2fd, #bbdefb); 
                       padding: 15px; border-radius: 8px; margin-bottom: 15px;
                       border-left: 4px solid #2196f3;'>
                <h4 style='margin: 0 0 10px 0; color: #0d47a1; font-size: 16px;'>üéØ C√°ch ti·∫øp c·∫≠n</h4>
                <p style='margin: 0; line-height: 1.7; color: #1565c0;'>{approach}</p>
            </div>
            """
        
        # Formulas or Rules - Improved
        formulas = topic.get('formulas_or_rules', [])
        if formulas:
            html += """
            <div style='background: #fff8e1; padding: 15px; border-radius: 8px; 
                       margin-bottom: 15px; border-left: 4px solid #ffa726;'>
                <h4 style='margin: 0 0 10px 0; color: #e65100; font-size: 16px;'>üìê C√¥ng th·ª©c/Quy t·∫Øc</h4>
                <ul style='margin: 0; padding-left: 20px;'>
            """
            for formula in formulas:
                html += f"""
                <li style='margin-bottom: 8px; font-family: "Courier New", monospace; 
                          background: white; padding: 8px; border-radius: 4px; 
                          font-size: 14px; border: 1px solid #ffe0b2;'>{formula}</li>
                """
            html += "</ul></div>"
        
        # Time Management Tip - Improved
        time_tip = topic.get('time_management_tip', '')
        if time_tip:
            html += f"""
            <div style='background: white; padding: 12px 15px; border-radius: 8px; 
                       border: 2px dashed #17a2b8; color: #0c5460;'>
                <strong>‚è±Ô∏è Qu·∫£n l√Ω th·ªùi gian:</strong> {time_tip}
            </div>
            """
        
        html += "</div>"  # Close topic card
    
    # Recommended Focus - Improved
    focus = study_data.get('recommended_focus', [])
    if focus:
        html += """
        <div style='background: linear-gradient(135deg, #ffeaa7 0%, #fdcb6e 100%); 
                    padding: 25px; border-radius: 15px; margin-bottom: 25px;
                    box-shadow: 0 4px 6px rgba(0,0,0,0.1);'>
            <h3 style='margin: 0 0 15px 0; color: #6c3483; font-size: 20px;'>
                üéØ ∆Øu ti√™n √¥n t·∫≠p ngay
            </h3>
            <ol style='margin: 0; padding-left: 20px; font-size: 16px;'>
        """
        for item in focus:
            html += f"<li style='margin-bottom: 10px; color: #6c3483; font-weight: 500;'>{item}</li>"
        html += "</ol></div>"
    
    # Next Steps - Improved
    next_steps = study_data.get('next_steps', '')
    if next_steps:
        html += f"""
        <div style='background: linear-gradient(135deg, #a8e6cf 0%, #56ccf2 100%); 
                    padding: 25px; border-radius: 15px; margin-bottom: 25px;
                    box-shadow: 0 4px 6px rgba(0,0,0,0.1);'>
            <h3 style='margin: 0 0 15px 0; color: #0d47a1; font-size: 20px;'>
                üìÖ L·ªô tr√¨nh √¥n t·∫≠p 7 ng√†y
            </h3>
            <p style='margin: 0; line-height: 1.8; color: #1565c0; font-size: 15px; white-space: pre-line;'>{next_steps}</p>
        </div>
        """
    
    # Practice Resources - Improved
    resources = study_data.get('practice_resources', [])
    if resources:
        html += """
        <div style='background: white; border: 2px solid #ffc107; 
                    padding: 25px; border-radius: 15px; margin-bottom: 25px;
                    box-shadow: 0 4px 6px rgba(0,0,0,0.1);'>
            <h3 style='margin: 0 0 15px 0; color: #f57c00; font-size: 20px;'>
                üìñ Ngu·ªìn t√†i li·ªáu h·ªçc t·∫≠p
            </h3>
            <ul style='margin: 0; padding-left: 20px; font-size: 15px;'>
        """
        for resource in resources:
            html += f"<li style='margin-bottom: 12px; line-height: 1.6; color: #e65100;'>{resource}</li>"
        html += "</ul></div>"
    
    # Motivation Message - Improved
    motivation = study_data.get('motivation_message', '')
    if motivation:
        html += f"""
        <div style='background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); 
                    color: white; padding: 30px; border-radius: 15px; text-align: center;
                    box-shadow: 0 6px 12px rgba(0,0,0,0.15);'>
            <h3 style='margin: 0 0 15px 0; font-size: 22px;'>üí™ L·ªùi ƒë·ªông vi√™n</h3>
            <p style='margin: 0; font-size: 17px; line-height: 1.8; font-style: italic; opacity: 0.95;'>
                "{motivation}"
            </p>
        </div>
        """
    
    html += "</div>"
    return html


def generate_study_guide_pdf(study_data: Dict[str, Any]) -> bytes:
    """
    Generate a beautifully formatted PDF from study guide data
    
    Args:
        study_data: Study guide dictionary from generate_study_guide()
    
    Returns:
        PDF file as bytes, or None if reportlab not available
    """
    
    def _register_vn_font():
        """Try to register a Unicode font that supports Vietnamese diacritics."""
        try:
            from reportlab.pdfbase import pdfmetrics
            from reportlab.pdfbase.ttfonts import TTFont
            font_candidates = [
                ("DejaVuSans", "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf"),
                ("NotoSans", "/usr/share/fonts/truetype/noto/NotoSans-Regular.ttf"),
                ("ArialUnicode", "C:/Windows/Fonts/ARIALUNI.TTF"),
                ("Arial", "C:/Windows/Fonts/arial.ttf"),
            ]
            for name, path in font_candidates:
                if Path(path).exists():
                    pdfmetrics.registerFont(TTFont(name, path))
                    return name
        except Exception:
            return None
        return None

    def clean_text_for_pdf(text, keep_unicode: bool):
        """Normalize text; optionally keep Unicode if font supports it."""
        if not isinstance(text, str):
            text = str(text)

        # Remove emojis/high codepoints that typical fonts can't render well
        text = ''.join(ch for ch in text if ord(ch) < 0x1F600 or ord(ch) > 0x1F64F)

        if keep_unicode:
            return text

        # Fallback ASCII mapping (old behavior)
        vietnamese_map = {
            '√†': 'a', '√°': 'a', '·∫£': 'a', '√£': 'a', '·∫°': 'a',
            'ƒÉ': 'a', '·∫±': 'a', '·∫Ø': 'a', '·∫≥': 'a', '·∫µ': 'a', '·∫∑': 'a',
            '√¢': 'a', '·∫ß': 'a', '·∫•': 'a', '·∫©': 'a', '·∫´': 'a', '·∫≠': 'a',
            '√®': 'e', '√©': 'e', '·∫ª': 'e', '·∫Ω': 'e', '·∫π': 'e',
            '√™': 'e', '·ªÅ': 'e', '·∫ø': 'e', '·ªÉ': 'e', '·ªÖ': 'e', '·ªá': 'e',
            '√¨': 'i', '√≠': 'i', '·ªâ': 'i', 'ƒ©': 'i', '·ªã': 'i',
            '√≤': 'o', '√≥': 'o', '·ªè': 'o', '√µ': 'o', '·ªç': 'o',
            '√¥': 'o', '·ªì': 'o', '·ªë': 'o', '·ªï': 'o', '·ªó': 'o', '·ªô': 'o',
            '∆°': 'o', '·ªù': 'o', '·ªõ': 'o', '·ªü': 'o', '·ª°': 'o', '·ª£': 'o',
            '√π': 'u', '√∫': 'u', '·ªß': 'u', '≈©': 'u', '·ª•': 'u',
            '∆∞': 'u', '·ª´': 'u', '·ª©': 'u', '·ª≠': 'u', '·ªØ': 'u', '·ª±': 'u',
            '·ª≥': 'y', '√Ω': 'y', '·ª∑': 'y', '·ªπ': 'y', '·ªµ': 'y',
            'ƒë': 'd', 'ƒê': 'D',
            '√Ä': 'A', '√Å': 'A', '·∫¢': 'A', '√É': 'A', '·∫†': 'A',
            'ƒÇ': 'A', '·∫∞': 'A', '·∫Æ': 'A', '·∫≤': 'A', '·∫¥': 'A', '·∫∂': 'A',
            '√Ç': 'A', '·∫¶': 'A', '·∫§': 'A', '·∫®': 'A', '·∫™': 'A', '·∫¨': 'A',
            '√à': 'E', '√â': 'E', '·∫∫': 'E', '·∫º': 'E', '·∫∏': 'E',
            '√ä': 'E', '·ªÄ': 'E', '·∫æ': 'E', '·ªÇ': 'E', '·ªÑ': 'E', '·ªÜ': 'E',
            '√å': 'I', '√ç': 'I', '·ªà': 'I', 'ƒ®': 'I', '·ªä': 'I',
            '√í': 'O', '√ì': 'O', '·ªé': 'O', '√ï': 'O', '·ªå': 'O',
            '√î': 'O', '·ªí': 'O', '·ªê': 'O', '·ªî': 'O', '·ªñ': 'O', '·ªò': 'O',
            '∆†': 'O', '·ªú': 'O', '·ªö': 'O', '·ªû': 'O', '·ª†': 'O', '·ª¢': 'O',
            '√ô': 'U', '√ö': 'U', '·ª¶': 'U', '≈®': 'U', '·ª§': 'U',
            '∆Ø': 'U', '·ª™': 'U', '·ª®': 'U', '·ª¨': 'U', '·ªÆ': 'U', '·ª∞': 'U',
            '·ª≤': 'Y', '√ù': 'Y', '·ª∂': 'Y', '·ª∏': 'Y', '·ª¥': 'Y',
        }
        for viet_char, ascii_char in vietnamese_map.items():
            text = text.replace(viet_char, ascii_char)
        cleaned = ''.join(ch for ch in text if ord(ch) < 128 or ch in '¬∞√ó√∑¬±')
        return cleaned
    
    try:
        from io import BytesIO
        from datetime import datetime
        
        # Try to import reportlab - if fails, show helpful message
        try:
            from reportlab.lib.pagesizes import letter, A4
            from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
            from reportlab.lib.units import inch
            from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak, Image
            from reportlab.lib import colors
            from reportlab.lib.enums import TA_CENTER, TA_LEFT, TA_JUSTIFY
        except ImportError:
            print("‚ö†Ô∏è ReportLab kh√¥ng ƒë∆∞·ª£c c√†i ƒë·∫∑t tr√™n Streamlit Cloud")
            print("üìã C√°ch kh·∫Øc ph·ª•c:")
            print("  1. Ki·ªÉm tra requirements.txt ƒë√£ c√≥ 'reportlab' ch∆∞a")
            print("  2. N·∫øu ch∆∞a, th√™m d√≤ng: reportlab")
            print("  3. Commit v√† push code")
            print("  4. Streamlit Cloud s·∫Ω t·ª± ƒë·ªông c√†i ƒë·∫∑t")
            return None
        
        # Try register Unicode font for Vietnamese
        font_name = _register_vn_font()
        unicode_font = bool(font_name)
        if not font_name:
            font_name = 'Helvetica'
        bold_font_name = font_name

        # Create PDF buffer
        pdf_buffer = BytesIO()
        
        # Create PDF document with A4 size
        doc = SimpleDocTemplate(
            pdf_buffer,
            pagesize=A4,
            rightMargin=0.75*inch,
            leftMargin=0.75*inch,
            topMargin=0.75*inch,
            bottomMargin=0.75*inch,
            title="Study Guide GMAT"
        )
        
        # Create styles
        styles = getSampleStyleSheet()
        
        # Custom styles
        title_style = ParagraphStyle(
            'CustomTitle',
            parent=styles['Heading1'],
            fontSize=24,
            textColor=colors.HexColor('#0066cc'),
            spaceAfter=12,
            alignment=TA_CENTER,
            fontName=bold_font_name
        )
        
        heading_style = ParagraphStyle(
            'CustomHeading',
            parent=styles['Heading2'],
            fontSize=14,
            textColor=colors.HexColor('#0066cc'),
            spaceAfter=6,
            spaceBefore=12,
            fontName=bold_font_name
        )
        
        subheading_style = ParagraphStyle(
            'SubHeading',
            parent=styles['Heading3'],
            fontSize=12,
            textColor=colors.HexColor('#333333'),
            spaceAfter=6,
            fontName=bold_font_name
        )
        
        body_style = ParagraphStyle(
            'CustomBody',
            parent=styles['BodyText'],
            fontSize=10,
            alignment=TA_JUSTIFY,
            spaceAfter=8,
            leading=14,
            fontName=font_name
        )
        
        # Story to hold all PDF elements
        story = []
        
        # Title
        story.append(Paragraph("TAI LIEU ON TAP GMAT CA NHAN HOA", title_style))
        story.append(Paragraph(f"Duoc tao vao: {datetime.now().strftime('%d/%m/%Y %H:%M')}", styles['Normal']))
        story.append(Spacer(1, 0.2*inch))
        
        # Overall summary
        overall = study_data.get('overall_summary', '')
        if overall:
            story.append(Paragraph("Tong Quan Ket Qua", heading_style))
            story.append(Paragraph(clean_text_for_pdf(overall, unicode_font), body_style))
            story.append(Spacer(1, 0.2*inch))
        
        # Topics
        topics = study_data.get('topics', [])
        for idx, topic in enumerate(topics):
            if idx > 0:
                story.append(PageBreak())
            
            topic_name = clean_text_for_pdf(topic.get('topic', 'Chu de'), unicode_font)
            stats = topic.get('stats', {})
            accuracy = (stats.get('correct', 0) / stats.get('total', 1) * 100) if stats.get('total', 1) > 0 else 0
            
            # Topic header
            story.append(Paragraph(topic_name, heading_style))
            
            # Statistics
            stats_text = f"Ket qua: {stats.get('correct', 0)}/{stats.get('total', 0)} dung ({accuracy:.0f}%)"
            story.append(Paragraph(stats_text, styles['Normal']))
            story.append(Spacer(1, 0.15*inch))
            
            # Theory
            theory = topic.get('theory', '')
            if theory:
                story.append(Paragraph("Ly Thuyet", subheading_style))
                # Handle both string and dictionary theory formats
                if isinstance(theory, str):
                    # Clean up theory text for better PDF rendering
                    theory_clean = clean_text_for_pdf(theory, unicode_font).replace('\n\n', '<br/><br/>').replace('\n', ' ')
                    story.append(Paragraph(theory_clean[:2000], body_style))  # Limit length
                elif isinstance(theory, dict):
                    # Convert dictionary theory to formatted text
                    theory_parts = []
                    if 'title' in theory:
                        theory_parts.append(f"<b>{clean_text_for_pdf(theory['title'], unicode_font)}</b>")
                    if 'definition' in theory:
                        theory_parts.append(f"<br/><b>Dinh nghia:</b> {clean_text_for_pdf(theory['definition'][:500], unicode_font)}")
                    if 'main_rules' in theory and theory['main_rules']:
                        theory_parts.append("<br/><b>Quy tac chinh:</b>")
                        for i, rule in enumerate(theory['main_rules'][:3], 1):
                            if isinstance(rule, dict):
                                rule_name = clean_text_for_pdf(rule.get('rule_name', ''), unicode_font)
                                theory_parts.append(f"<br/>{i}. {rule_name}")
                            else:
                                theory_parts.append(f"<br/>{i}. {clean_text_for_pdf(str(rule), unicode_font)}")
                    theory_text = ' '.join(theory_parts)[:2000]  # Limit total length
                    story.append(Paragraph(theory_text, body_style))
                else:
                    # Fallback for other types
                    story.append(Paragraph(clean_text_for_pdf(str(theory), unicode_font)[:2000], body_style))
                story.append(Spacer(1, 0.1*inch))
            
            # Detailed concepts
            concepts = topic.get('detailed_concepts', [])
            if concepts:
                story.append(Paragraph("Cac Khai Niem Chi Tiet", subheading_style))
                for concept in concepts[:3]:  # Limit to 3 concepts
                    concept_name = clean_text_for_pdf(concept.get('concept_name', ''), unicode_font)
                    explanation = clean_text_for_pdf(concept.get('explanation', ''), unicode_font)
                    story.append(Paragraph(f"<b>‚Ä¢ {concept_name}:</b>", body_style))
                    story.append(Paragraph(explanation, body_style))
                story.append(Spacer(1, 0.1*inch))
            
            # Step by step method
            steps = topic.get('step_by_step_method', [])
            if steps:
                story.append(Paragraph("Phuong Phap Tung Buoc", subheading_style))
                for i, step in enumerate(steps, 1):
                    story.append(Paragraph(f"<b>Buoc {i}:</b> {clean_text_for_pdf(step, unicode_font)}", body_style))
                story.append(Spacer(1, 0.1*inch))
            
            # Common mistakes
            mistakes = topic.get('common_mistakes', [])
            if mistakes:
                story.append(Paragraph("Loi Pho Bien", subheading_style))
                for mistake in mistakes[:4]:  # Limit to 4 mistakes
                    story.append(Paragraph(f"‚Ä¢ {clean_text_for_pdf(mistake, unicode_font)}", body_style))
                story.append(Spacer(1, 0.1*inch))
            
            # Tips
            tips_accuracy = topic.get('tips_for_accuracy', [])
            if tips_accuracy:
                story.append(Paragraph("Meo Tang Ty Le Dung", subheading_style))
                for tip in tips_accuracy[:3]:  # Limit to 3 tips
                    story.append(Paragraph(f"‚Ä¢ {clean_text_for_pdf(tip, unicode_font)}", body_style))
            
            tips_speed = topic.get('tips_for_speed', [])
            if tips_speed:
                story.append(Paragraph("Meo Tang Toc Do", subheading_style))
                for tip in tips_speed[:2]:  # Limit to 2 tips
                    story.append(Paragraph(f"‚Ä¢ {clean_text_for_pdf(tip, unicode_font)}", body_style))
            
            # Practice drills
            drills = topic.get('practice_drills', [])
            if drills:
                story.append(Spacer(1, 0.1*inch))
                story.append(Paragraph("Bai Tap Luyen Tap", subheading_style))
                for drill in drills[:4]:  # Limit to 4 drills
                    story.append(Paragraph(f"‚Ä¢ {clean_text_for_pdf(drill, unicode_font)}", body_style))
            
            # Key formulas
            formulas = topic.get('key_formulas', [])
            if formulas:
                story.append(Spacer(1, 0.1*inch))
                story.append(Paragraph("Cong Thuc Can Nho", subheading_style))
                for formula in formulas[:4]:  # Limit to 4 formulas
                    story.append(Paragraph(f"‚Ä¢ {clean_text_for_pdf(formula, unicode_font)}", body_style))
        
        # Build PDF
        doc.build(story)
        
        # Get PDF bytes
        pdf_bytes = pdf_buffer.getvalue()
        pdf_buffer.close()
        
        return pdf_bytes
        
    except ImportError as e:
        print(f"‚ö†Ô∏è L·ªói: C·∫ßn c√†i ƒë·∫∑t reportlab. Ch·∫°y: pip install reportlab")
        print(f"Chi ti·∫øt l·ªói: {e}")
        return None
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói t·∫°o PDF: {e}")
        import traceback
        traceback.print_exc()
        return None


def generate_study_guide_text_formatted(study_data: Dict[str, Any]) -> str:
    """
    Generate a beautifully formatted text document (alternative to PDF)
    Can be easily converted to PDF using online tools
    
    Args:
        study_data: Study guide dictionary
    
    Returns:
        Formatted text content as string
    """
    from datetime import datetime
    
    text = ""
    
    # Title
    text += "=" * 80 + "\n"
    text += "T√ÄI LI·ªÜU √îN T·∫¨P GMAT C√Å NH√ÇN H√ìA\n"
    text += "=" * 80 + "\n\n"
    text += f"ƒê∆∞·ª£c t·∫°o v√†o: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\n\n"
    
    # Overall summary
    overall = study_data.get('overall_summary', '')
    if overall:
        text += "üìä T·ªîNG QUAN K·∫æT QU·∫¢\n"
        text += "-" * 80 + "\n"
        text += overall + "\n\n"
    
    # Topics
    topics = study_data.get('topics', [])
    for idx, topic in enumerate(topics, 1):
        if idx > 1:
            text += "\n" + "=" * 80 + "\n"
        
        topic_name = topic.get('topic', 'Ch·ªß ƒë·ªÅ')
        stats = topic.get('stats', {})
        accuracy = (stats.get('correct', 0) / stats.get('total', 1) * 100) if stats.get('total', 1) > 0 else 0
        
        # Topic header
        text += f"\nCH·ª¶ ƒê·ªÄ {idx}: {topic_name}\n"
        text += "=" * 80 + "\n"
        text += f"K·∫øt qu·∫£: {stats.get('correct', 0)}/{stats.get('total', 0)} ƒë√∫ng ({accuracy:.0f}%)\n\n"
        
        # Theory
        theory = topic.get('theory', '')
        if theory:
            text += "L√ù THUY·∫æT\n"
            text += "-" * 80 + "\n"
            # Handle both string and dictionary theory formats
            if isinstance(theory, str):
                text += theory + "\n\n"
            elif isinstance(theory, dict):
                # Convert dictionary theory to formatted text
                if 'title' in theory:
                    text += f"{theory['title']}\n\n"
                if 'definition' in theory:
                    text += f"ƒê·ªäNH NGHƒ®A:\n{theory['definition']}\n\n"
                if 'main_rules' in theory and theory['main_rules']:
                    text += "QUY T·∫ÆC CH√çNH:\n"
                    for i, rule in enumerate(theory['main_rules'], 1):
                        if isinstance(rule, dict):
                            text += f"{i}. {rule.get('rule_name', '')}\n"
                            if rule.get('formula'):
                                text += f"   C√¥ng th·ª©c: {rule['formula']}\n"
                            if rule.get('explanation'):
                                text += f"   {rule['explanation']}\n"
                        else:
                            text += f"{i}. {rule}\n"
                    text += "\n"
                if 'application_steps' in theory and theory['application_steps']:
                    steps_data = theory['application_steps']
                    if isinstance(steps_data, dict) and 'steps' in steps_data:
                        text += f"{steps_data.get('title', 'C√ÅC B∆Ø·ªöC √ÅP D·ª§NG')}:\n"
                        for i, step in enumerate(steps_data['steps'], 1):
                            text += f"{i}. {step}\n"
                        text += "\n"
                if 'example_analysis' in theory and theory['example_analysis']:
                    example = theory['example_analysis']
                    if isinstance(example, dict):
                        text += "V√ç D·ª§ MINH H·ªåA:\n"
                        if 'sequence' in example:
                            text += f"D√£y: {example['sequence']}\n"
                        if 'solution' in example:
                            text += f"L·ªùi gi·∫£i: {example['solution']}\n"
                        text += "\n"
                if 'important_notes' in theory:
                    text += f"L∆ØU √ù QUAN TR·ªåNG:\n{theory['important_notes']}\n\n"
            else:
                text += str(theory) + "\n\n"
        
        # Detailed concepts
        concepts = topic.get('detailed_concepts', [])
        if concepts:
            text += "C√ÅC KH√ÅI NI·ªÜM CHI TI·∫æT\n"
            text += "-" * 80 + "\n"
            for i, concept in enumerate(concepts, 1):
                concept_name = concept.get('concept_name', '')
                explanation = concept.get('explanation', '')
                example = concept.get('example', '')
                text += f"\n{i}. {concept_name}\n"
                text += f"   Gi·∫£i th√≠ch: {explanation}\n"
                if example:
                    text += f"   V√≠ d·ª•: {example}\n"
            text += "\n"
        
        # Step by step method
        steps = topic.get('step_by_step_method', [])
        if steps:
            text += "PH∆Ø∆†NG PH√ÅP T·ª™NG B∆Ø·ªöC\n"
            text += "-" * 80 + "\n"
            for i, step in enumerate(steps, 1):
                text += f"{i}. {step}\n"
            text += "\n"
        
        # Common mistakes
        mistakes = topic.get('common_mistakes', [])
        if mistakes:
            text += "L·ªñI PH·ªî BI·∫æN\n"
            text += "-" * 80 + "\n"
            for mistake in mistakes[:5]:
                text += f"‚Ä¢ {mistake}\n"
            text += "\n"
        
        # Tips
        tips_accuracy = topic.get('tips_for_accuracy', [])
        if tips_accuracy:
            text += "M·∫∏O TƒÇNG T·ª∂ L·ªÜ ƒê√öNG\n"
            text += "-" * 80 + "\n"
            for tip in tips_accuracy[:4]:
                text += f"‚Ä¢ {tip}\n"
            text += "\n"
        
        tips_speed = topic.get('tips_for_speed', [])
        if tips_speed:
            text += "M·∫∏O TƒÇNG T·ªêC ƒê·ªò\n"
            text += "-" * 80 + "\n"
            for tip in tips_speed[:3]:
                text += f"‚Ä¢ {tip}\n"
            text += "\n"
        
        # Practice drills
        drills = topic.get('practice_drills', [])
        if drills:
            text += "B√ÄI T·∫¨P LUY·ªÜN T·∫¨P\n"
            text += "-" * 80 + "\n"
            for drill in drills[:4]:
                text += f"‚Ä¢ {drill}\n"
            text += "\n"
        
        # Key formulas
        formulas = topic.get('key_formulas', [])
        if formulas:
            text += "C√îNG TH·ª®C C·∫¶N NH·ªö\n"
            text += "-" * 80 + "\n"
            for formula in formulas[:5]:
                text += f"‚Ä¢ {formula}\n"
            text += "\n"
    
    text += "\n" + "=" * 80 + "\n"
    text += "H·∫æT\n"
    text += "=" * 80 + "\n"
    
    return text
