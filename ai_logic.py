import google.generativeai as genai
import json
import os
import random
import re
from difflib import SequenceMatcher
from dotenv import load_dotenv
import time
from db import save_questions, get_cached_questions
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import lru_cache

# Load environment variables
load_dotenv()

# --- C·∫§U H√åNH (Lazy init ƒë·ªÉ kh√¥ng g·ªçi Streamlit tr∆∞·ªõc set_page_config) ---

@lru_cache(maxsize=1)
def _get_api_key() -> str | None:
    """Fetch API key from env first; fallback to Streamlit secrets lazily.
    Avoid accessing streamlit at import time to keep set_page_config as first command.
    """
    key = os.getenv("GEMINI_API_KEY")
    if key:
        return key
    try:
        import streamlit as st  # imported lazily, after app has configured
        return st.secrets.get("GEMINI_API_KEY")
    except Exception:
        return None


@lru_cache(maxsize=1)
def _get_model():
    key = _get_api_key()
    if not key:
        print("GEMINI_API_KEY not found. Set in environment or Streamlit secrets.")
        return None
    try:
        genai.configure(api_key=key)
        return genai.GenerativeModel('gemma-3-12b-it')
    except Exception as e:
        print(f"L·ªói kh·ªüi t·∫°o Gemini: {e}")
        return None

def _clean_response_text(response) -> str:
    """Extracts the first text part and strips code fences/whitespace/control chars."""
    text = None
    try:
        text = response.text
    except Exception:
        pass

    if not text:
        try:
            text = response.candidates[0].content.parts[0].text  # best-effort fallback
        except Exception:
            text = ""

    # Remove markdown code fences
    text = text.replace('```json', '').replace('```', '').strip()
    
    # Remove control characters that break JSON (except \n, \r, \t)
    import re
    text = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', text)
    
    return text
def _align_correct_answer(options: list, correct_answer: str) -> str | None:
    """Best-effort map correct_answer to one of the provided options.

    - Accept exact match
    - Accept letter prefix match (A/B/C/D)
    - Accept content match after stripping prefixes like "A." or "A)"
    - Fallback to similarity score to handle minor variations
    """
    if not options or not correct_answer:
        return None

    cleaned_opts = []
    seen = set()
    for opt in options:
        if not isinstance(opt, str):
            continue
        opt_clean = opt.strip()
        if opt_clean and opt_clean not in seen:
            cleaned_opts.append(opt_clean)
            seen.add(opt_clean)

    if not cleaned_opts:
        return None

    correct_clean = correct_answer.strip()

    # 1) Exact match
    for opt in cleaned_opts:
        if correct_clean == opt:
            return opt

    # Helper to strip letter prefix
    def strip_prefix(val: str) -> str:
        return re.sub(r'^[A-D][\.\)]\s*', '', (val or '').strip(), flags=re.IGNORECASE)

    # 2) Match by letter prefix (A/B/C/D)
    if correct_clean:
        letter = correct_clean[:1].upper()
        if letter in "ABCD":
            for opt in cleaned_opts:
                if opt.upper().startswith(letter):
                    return opt

    # 3) Match by content after removing prefix
    normalized_correct = strip_prefix(correct_clean).lower()
    if normalized_correct:
        for opt in cleaned_opts:
            if strip_prefix(opt).lower() == normalized_correct:
                return opt

    # 4) Fallback: similarity match
    best_opt, best_ratio = None, 0.0
    for opt in cleaned_opts:
        ratio = SequenceMatcher(None, strip_prefix(opt).lower(), normalized_correct).ratio()
        if ratio > best_ratio:
            best_opt, best_ratio = opt, ratio
    if best_opt and best_ratio >= 0.8:
        return best_opt

    return None


def generate_question_variant(seed_question, max_attempts: int = 3):
    """T·∫°o 1 bi·∫øn th·ªÉ c√¢u h·ªèi (d√πng cho h√†m batch b√™n d∆∞·ªõi) v·ªõi retry khi JSON l·ªói."""
    model = _get_model()
    if model is None:
        print("‚ùå Model kh√¥ng ƒë∆∞·ª£c kh·ªüi t·∫°o")
        return None

    topic = seed_question.get('topic', 'Ki·∫øn th·ª©c t·ªïng h·ª£p')
    is_visual = topic.lower() in ['pattern recognition', 'letter pattern', 'logic puzzle', 'number pattern']
    
    prompt = f"""
    ƒê√≥ng vai ng∆∞·ªùi ra ƒë·ªÅ thi GMAT.
    Ch·ªß ƒë·ªÅ: {topic}
    C√¢u m·∫´u: "{seed_question['content']}"

    Nhi·ªám v·ª•: T·∫°o 1 c√¢u h·ªèi tr·∫Øc nghi·ªám M·ªöI:
    - N·∫øu l√† to√°n/logic: gi·ªØ nguy√™n d·∫°ng to√°n/logic nh∆∞ng thay s·ªë li·ªáu/b·ªëi c·∫£nh
    - N·∫øu l√† ki·∫øn th·ª©c: c√πng ch·ªß ƒë·ªÅ nh∆∞ng h·ªèi kh√≠a c·∫°nh kh√°c
    - N·∫øu l√† IQ/pattern (d√£y s·ªë, ch·ªØ c√°i, h√¨nh h·ªçc): t·∫°o d√£y logic m·ªõi, M√î T·∫¢ b·∫±ng text thu·∫ßn, KH√îNG c·∫ßn h√¨nh ·∫£nh th·ª±c
    - T√çNH TO√ÅN C·∫®N TH·∫¨N: v·ªõi b√†i t√≠nh ph·∫ßn trƒÉm tƒÉng/gi·∫£m, d√πng c√¥ng th·ª©c (gi√°_m·ªõi - gi√°_c≈©)/gi√°_c≈© * 100 v√† ki·ªÉm tra l·∫°i k·∫øt qu·∫£ tr∆∞·ªõc khi tr·∫£ l·ªùi.

    R√†ng bu·ªôc ƒë·ªãnh d·∫°ng:
    - Ch·ªâ d√πng k√Ω t·ª± ASCII, kh√¥ng k√Ω t·ª± ƒë·∫∑c bi·ªát ph·ª©c t·∫°p, kh√¥ng emoji.
    - Kh√¥ng xu·ªëng d√≤ng trong gi√° tr·ªã chu·ªói.
    - Kh√¥ng d√πng Markdown, kh√¥ng bao c√°c block ```json.
    - Tr·∫£ v·ªÅ DUY NH·∫§T m·ªôt JSON object h·ª£p l·ªá.

    OUTPUT JSON duy nh·∫•t:
    {{
        "id": "new_id",
        "type": "general",
        "question": "No newline. Short and clear. For pattern/sequence questions, describe the pattern in text (e.g. 1,2,4,7,11,... (?)).",
        "options": ["A. ...", "B. ...", "C. ...", "D. ..."],
        "correct_answer": "Copy exact text of the correct option",
        "explanation": "Brief reasoning (show key calculation or pattern rule)"
    }}
    """

    for attempt in range(1, max_attempts + 1):
        try:
            # Add generation config for better JSON output
            response = model.generate_content(
                prompt,
                generation_config={
                    'temperature': 0.7,
                    'max_output_tokens': 1024
                }
            )
            clean_text = _clean_response_text(response)
            data = json.loads(clean_text)
            data['type'] = 'general'  # T·∫•t c·∫£ ƒë·ªÅu l√† c√¢u h·ªèi chung

            # ƒê·∫£m b·∫£o ƒë√°p √°n kh·ªõp v·ªõi m·ªôt l·ª±a ch·ªçn
            options = data.get('options') or []
            correct = data.get('correct_answer') or ''
            aligned = _align_correct_answer(options, correct)
            if not aligned:
                raise ValueError("Correct answer does not align with options")

            # Chu·∫©n h√≥a l·∫°i danh s√°ch l·ª±a ch·ªçn v√† ƒë√°p √°n ƒë·ªÉ hi·ªÉn th·ªã nh·∫•t qu√°n
            cleaned_opts = []
            seen = set()
            for opt in options:
                if not isinstance(opt, str):
                    continue
                opt_clean = opt.strip()
                if opt_clean and opt_clean not in seen:
                    cleaned_opts.append(opt_clean)
                    seen.add(opt_clean)

            data['options'] = cleaned_opts
            data['correct_answer'] = aligned
            return data
        except json.JSONDecodeError as e:
            print(f"‚ùå L·ªói JSON (attempt {attempt}/{max_attempts}): {e}")
            print(f"Response text: {clean_text[:200]}")
            if attempt < max_attempts:
                time.sleep(1 * attempt)  # Exponential backoff
        except Exception as e:
            print(f"‚ùå L·ªói khi t·∫°o c√¢u (attempt {attempt}/{max_attempts}): {e}")
            if attempt < max_attempts:
                time.sleep(2 * attempt)  # Exponential backoff

    return None

def generate_question_batch(seeds, start_idx=0, progress_callback=None):
    """Generate multiple questions concurrently"""
    results = []
    visual_keywords = ['h√¨nh', 'shape', '·∫£nh', 'diagram', 'figure', 'bi·ªÉu ƒë·ªì']

    def _extract_number(text: str) -> float | None:
        nums = re.findall(r"\d+(?:[.,]\d+)?", text or "")
        if len(nums) < 2:
            return None
        try:
            old_v = float(nums[0].replace(',', '.'))
            new_v = float(nums[1].replace(',', '.'))
            if old_v == 0:
                return None
            pct = round((new_v - old_v) / old_v * 100, 2)
            return pct
        except Exception:
            return None

    def _is_percent_increase_question(text: str) -> bool:
        t = (text or '').lower()
        return 'tƒÉng' in t and 't·ª´' in t and ('l√™n' in t or 'th√†nh' in t)

    def _percent_answer_matches(q: dict) -> bool:
        question = q.get('question', '')
        if not _is_percent_increase_question(question):
            return True  # not a percent-change question
        expected = _extract_number(question)
        if expected is None:
            return True

        def _first_number(val: str) -> float | None:
            m = re.search(r"-?\d+(?:[.,]\d+)?", val or "")
            if not m:
                return None
            try:
                return float(m.group(0).replace(',', '.'))
            except Exception:
                return None

        options = q.get('options') or []
        correct = q.get('correct_answer') or ''
        correct_num = _first_number(correct)
        # Accept if correct_answer has number close to expected
        if correct_num is not None and abs(correct_num - expected) <= 0.6:
            return True
        # Else check if any option matches expected closely
        for opt in options:
            num = _first_number(opt)
            if num is not None and abs(num - expected) <= 0.6:
                return True
        return False

    def _is_valid(q: dict) -> bool:
        """Basic sanity checks to avoid garbage answers."""
        if not q:
            return False
        options = q.get('options') or []
        if len(options) < 2:
            return False
        correct = q.get('correct_answer') or ''
        has_option_match = False
        # Accept if exact match to an option
        if correct in options:
            has_option_match = True
        # Accept if the letter prefix matches one option's prefix (e.g., 'A.' or 'A ')
        if correct:
            letter = correct.strip()[:2]  # e.g., "A." or "A "
            for opt in options:
                if opt.strip().startswith(letter):
                    has_option_match = True
        if not has_option_match:
            return False
        # Additional semantic check for percent-increase questions
        if not _percent_answer_matches(q):
            return False
        return True
    
    with ThreadPoolExecutor(max_workers=3) as executor:
        # Submit all tasks
        future_to_idx = {executor.submit(generate_question_variant, seed): (idx, seed) 
                        for idx, seed in enumerate(seeds)}
        
        # Process completed tasks
        for future in as_completed(future_to_idx):
            idx, seed = future_to_idx[future]
            try:
                new_q = future.result()
                if new_q:
                    text = (new_q.get('question') or '').lower()
                    has_image = bool(new_q.get('image_url'))
                    if any(k in text for k in visual_keywords) and not has_image:
                        print(f"üö´ B·ªè qua c√¢u h·ªèi thi·∫øu h√¨nh ·∫£nh: {text[:60]}...")
                    elif not _is_valid(new_q):
                        print(f"üö´ B·ªè qua c√¢u h·ªèi sai ƒë·ªãnh d·∫°ng ƒë√°p √°n")
                    else:
                        results.append(new_q)
                        print(f"‚úÖ C√¢u {start_idx + idx + 1} - T·∫°o th√†nh c√¥ng")
                else:
                    print(f"‚ö†Ô∏è C√¢u {start_idx + idx + 1} - Th·∫•t b·∫°i")
            except Exception as e:
                print(f"‚ùå L·ªói khi t·∫°o c√¢u {start_idx + idx + 1}: {e}")
            
            if progress_callback:
                progress_callback((start_idx + idx + 1) / (start_idx + len(seeds)))
    
    return results

def generate_full_exam(seed_data, num_questions=30, num_general=0, progress_callback=None, max_retries_per_question=4):
    """
    T·∫°o b·ªô ƒë·ªÅ thi ho√†n ch·ªânh v·ªõi c∆° ch·∫ø concurrent execution v√† retry ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô.
    - num_questions: T·ªïng s·ªë c√¢u h·ªèi c·∫ßn t·∫°o
    - num_general: Tham s·ªë c≈© ƒë·ªÉ t∆∞∆°ng th√≠ch, b·ªè qua
    - max_retries_per_question: S·ªë l·∫ßn th·ª≠ l·∫°i t·ªëi ƒëa cho m·ªói c√¢u th·∫•t b·∫°i
    """
    exam_questions = []

    if not seed_data:
        print("‚ùå Kh√¥ng c√≥ seed data")
        return exam_questions

    print(f"üìã B·∫Øt ƒë·∫ßu t·∫°o {num_questions} c√¢u h·ªèi t·ª´ {len(seed_data)} c√¢u m·∫´u (concurrent mode)...")

    # Try to get from cache first
    cached = get_cached_questions(num_questions, randomize=True)
    if len(cached) >= num_questions:
        print(f"‚úÖ S·ª≠ d·ª•ng {num_questions} c√¢u t·ª´ cache")
        return cached[:num_questions]
    
    # Diversify seed selection: group by topic, pick from each bucket
    topic_buckets = {}
    for s in seed_data:
        t = s.get('topic', 'general')
        topic_buckets.setdefault(t, []).append(s)
    
    selected_seeds = []
    bucket_list = list(topic_buckets.values())
    random.shuffle(bucket_list)
    while len(selected_seeds) < num_questions and bucket_list:
        for bucket in bucket_list:
            if bucket:
                selected_seeds.append(random.choice(bucket))
                if len(selected_seeds) >= num_questions:
                    break
    # Fallback if not enough
    if len(selected_seeds) < num_questions:
        selected_seeds.extend(random.choices(seed_data, k=num_questions - len(selected_seeds)))
    total_tasks = len(selected_seeds)

    # Concurrent generation - batch processing
    exam_questions = generate_question_batch(selected_seeds, 0, progress_callback)

    # Retry with concurrent processing for failed questions
    if len(exam_questions) < num_questions:
        remaining = num_questions - len(exam_questions)
        print(f"üîÅ B·∫Øt ƒë·∫ßu th·ª≠ l·∫°i cho {remaining} c√¢u l·ªói (concurrent retry)...")
        retry_pool = random.choices(seed_data, k=remaining * 2)  # Generate more to increase success rate
        
        retry_results = generate_question_batch(retry_pool, len(exam_questions), progress_callback)
        exam_questions.extend(retry_results[:remaining])

    # Ki·ªÉm tra c√¢u tr√πng l·∫∑p d·ª±a tr√™n n·ªôi dung c√¢u h·ªèi (optimized)
    def normalize(txt: str) -> str:
        import string
        return txt.lower().translate(str.maketrans('', '', string.punctuation)).strip()
    
    seen_questions = set()
    unique_questions = []
    
    for q in exam_questions:
        question_text = normalize(q.get('question', ''))
        if question_text and question_text not in seen_questions:
            unique_questions.append(q)
            seen_questions.add(question_text)
    
    exam_questions = unique_questions
    print(f"‚úÖ Lo·∫°i b·ªè tr√πng l·∫∑p: c√≤n {len(exam_questions)} c√¢u duy nh·∫•t")
    
    # Save to cache for future use
    if exam_questions:
        try:
            saved_count = save_questions(exam_questions)
            print(f"üíæ ƒê√£ l∆∞u {saved_count} c√¢u v√†o DB cache")
        except Exception as e:
            print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ l∆∞u DB: {e}")
    
    # Fallback: use cache if still not enough
    if len(exam_questions) < num_questions:
        need_fill = num_questions - len(exam_questions)
        print(f"‚ö†Ô∏è C√≤n thi·∫øu {need_fill} c√¢u, s·ª≠ d·ª•ng cache ƒë·ªÉ b·ªï sung...")
        
        cached = get_cached_questions(need_fill * 2, randomize=True)
        for q in cached:
            q_text = normalize(q.get('question', ''))
            if q_text and q_text not in seen_questions:
                exam_questions.append(q)
                seen_questions.add(q_text)
                if len(exam_questions) >= num_questions:
                    break

    # X√°o tr·ªôn th·ª© t·ª± c√¢u h·ªèi NHI·ªÄU L·∫¶N ƒë·ªÉ ƒë·∫£m b·∫£o ng·∫´u nhi√™n ho√†n to√†n
    random.shuffle(exam_questions)
    random.shuffle(exam_questions)  # double shuffle for extra randomness
    
    if len(exam_questions) < num_questions:
        print(f"‚ö†Ô∏è C·∫£nh b√°o: Ch·ªâ t·∫°o ƒë∆∞·ª£c {len(exam_questions)}/{num_questions} c√¢u. Vui l√≤ng ki·ªÉm tra API key ho·∫∑c th·ª≠ l·∫°i.")
    else:
        print(f"üéâ T·∫°o xong {len(exam_questions)} c√¢u h·ªèi (kh√¥ng tr√πng l·∫∑p, th·ª© t·ª± ng·∫´u nhi√™n)")
    
    return exam_questions