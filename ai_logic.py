import google.generativeai as genai
import json
import os
import random
from dotenv import load_dotenv
import time
from db import save_questions, get_cached_questions
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import lru_cache

# Load environment variables
load_dotenv()

# --- Cáº¤U HÃŒNH (Lazy init Ä‘á»ƒ khÃ´ng gá»i Streamlit trÆ°á»›c set_page_config) ---

@lru_cache(maxsize=1)
def _get_api_key() -> str | None:
    """Fetch API key from env first; fallback to Streamlit secrets lazily.
    Avoid accessing streamlit at import time to keep set_page_config as first command.
    """
    key = os.getenv("GEMINI_API_KEY")
    if key:
        return key
    try:
        import streamlit as st  # imported lazily, after app has configured
        return st.secrets.get("GEMINI_API_KEY")
    except Exception:
        return None


@lru_cache(maxsize=1)
def _get_model():
    key = _get_api_key()
    if not key:
        print("GEMINI_API_KEY not found. Set in environment or Streamlit secrets.")
        return None
    try:
        genai.configure(api_key=key)
        return genai.GenerativeModel('gemma-3-12b-it')
    except Exception as e:
        print(f"Lá»—i khá»Ÿi táº¡o Gemini: {e}")
        return None

def _clean_response_text(response) -> str:
    """Extracts the first text part and strips code fences/whitespace."""
    text = None
    try:
        text = response.text
    except Exception:
        pass

    if not text:
        try:
            text = response.candidates[0].content.parts[0].text  # best-effort fallback
        except Exception:
            text = ""

    return (
        text.replace('```json', '')
            .replace('```', '')
            .strip()
    )


def generate_question_variant(seed_question, max_attempts: int = 3):
    """Táº¡o 1 biáº¿n thá»ƒ cÃ¢u há»i (dÃ¹ng cho hÃ m batch bÃªn dÆ°á»›i) vá»›i retry khi JSON lá»—i."""
    model = _get_model()
    if model is None:
        print("âŒ Model khÃ´ng Ä‘Æ°á»£c khá»Ÿi táº¡o")
        return None

    prompt = f"""
    ÄÃ³ng vai ngÆ°á»i ra Ä‘á» thi GMAT.
    Chá»§ Ä‘á»: {seed_question.get('topic', 'Kiáº¿n thá»©c tá»•ng há»£p')}
    CÃ¢u máº«u: "{seed_question['content']}"

    Nhiá»‡m vá»¥: Táº¡o 1 cÃ¢u há»i tráº¯c nghiá»‡m Má»šI:
    - Náº¿u lÃ  toÃ¡n/logic: giá»¯ nguyÃªn dáº¡ng toÃ¡n/logic nhÆ°ng thay sá»‘ liá»‡u/bá»‘i cáº£nh
    - Náº¿u lÃ  kiáº¿n thá»©c: cÃ¹ng chá»§ Ä‘á» nhÆ°ng há»i khÃ­a cáº¡nh khÃ¡c

    RÃ ng buá»™c Ä‘á»‹nh dáº¡ng:
    - Chá»‰ dÃ¹ng kÃ½ tá»± ASCII, khÃ´ng kÃ½ tá»± Ä‘áº·c biá»‡t, khÃ´ng emoji.
    - KhÃ´ng xuá»‘ng dÃ²ng trong giÃ¡ trá»‹ chuá»—i.
    - KhÃ´ng dÃ¹ng Markdown, khÃ´ng bao cÃ¡c block ```json.
    - Tráº£ vá» DUY NHáº¤T má»™t JSON object há»£p lá»‡.

    OUTPUT JSON duy nháº¥t:
    {{
        "id": "new_id",
        "type": "general",
        "question": "No newline. Short and clear.",
        "options": ["A. ...", "B. ...", "C. ...", "D. ..."],
        "correct_answer": "Copy exact text of the correct option",
        "explanation": "Brief reasoning"
    }}
    """

    for attempt in range(1, max_attempts + 1):
        try:
            response = model.generate_content(prompt)
            clean_text = _clean_response_text(response)
            data = json.loads(clean_text)
            data['type'] = 'general'  # Táº¥t cáº£ Ä‘á»u lÃ  cÃ¢u há»i chung
            return data
        except json.JSONDecodeError as e:
            print(f"âŒ Lá»—i JSON (attempt {attempt}/{max_attempts}): {e}")
            print(f"Response text: {clean_text[:200]}")
        except Exception as e:
            print(f"âŒ Lá»—i khi táº¡o cÃ¢u (attempt {attempt}/{max_attempts}): {e}")

    return None

def generate_question_batch(seeds, start_idx=0, progress_callback=None):
    """Generate multiple questions concurrently"""
    results = []
    visual_keywords = ['hÃ¬nh', 'shape', 'áº£nh', 'diagram', 'figure', 'biá»ƒu Ä‘á»“']
    
    with ThreadPoolExecutor(max_workers=5) as executor:
        # Submit all tasks
        future_to_idx = {executor.submit(generate_question_variant, seed): (idx, seed) 
                        for idx, seed in enumerate(seeds)}
        
        # Process completed tasks
        for future in as_completed(future_to_idx):
            idx, seed = future_to_idx[future]
            try:
                new_q = future.result()
                if new_q:
                    text = (new_q.get('question') or '').lower()
                    has_image = bool(new_q.get('image_url'))
                    if any(k in text for k in visual_keywords) and not has_image:
                        print(f"ğŸš« Bá» qua cÃ¢u há»i thiáº¿u hÃ¬nh áº£nh: {text[:60]}...")
                    else:
                        results.append(new_q)
                        print(f"âœ… CÃ¢u {start_idx + idx + 1} - Táº¡o thÃ nh cÃ´ng")
                else:
                    print(f"âš ï¸ CÃ¢u {start_idx + idx + 1} - Tháº¥t báº¡i")
            except Exception as e:
                print(f"âŒ Lá»—i khi táº¡o cÃ¢u {start_idx + idx + 1}: {e}")
            
            if progress_callback:
                progress_callback((start_idx + idx + 1) / (start_idx + len(seeds)))
    
    return results

def generate_full_exam(seed_data, num_questions=30, num_general=0, progress_callback=None, max_retries_per_question=4):
    """
    Táº¡o bá»™ Ä‘á» thi hoÃ n chá»‰nh vá»›i cÆ¡ cháº¿ concurrent execution vÃ  retry Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™.
    - num_questions: Tá»•ng sá»‘ cÃ¢u há»i cáº§n táº¡o
    - num_general: Tham sá»‘ cÅ© Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch, bá» qua
    - max_retries_per_question: Sá»‘ láº§n thá»­ láº¡i tá»‘i Ä‘a cho má»—i cÃ¢u tháº¥t báº¡i
    """
    exam_questions = []

    if not seed_data:
        print("âŒ KhÃ´ng cÃ³ seed data")
        return exam_questions

    print(f"ğŸ“‹ Báº¯t Ä‘áº§u táº¡o {num_questions} cÃ¢u há»i tá»« {len(seed_data)} cÃ¢u máº«u (concurrent mode)...")

    # Try to get from cache first
    cached = get_cached_questions(num_questions, randomize=True)
    if len(cached) >= num_questions:
        print(f"âœ… Sá»­ dá»¥ng {num_questions} cÃ¢u tá»« cache")
        return cached[:num_questions]
    
    selected_seeds = random.choices(seed_data, k=num_questions)
    total_tasks = len(selected_seeds)

    # Concurrent generation - batch processing
    exam_questions = generate_question_batch(selected_seeds, 0, progress_callback)

    # Retry with concurrent processing for failed questions
    if len(exam_questions) < num_questions:
        remaining = num_questions - len(exam_questions)
        print(f"ğŸ” Báº¯t Ä‘áº§u thá»­ láº¡i cho {remaining} cÃ¢u lá»—i (concurrent retry)...")
        retry_pool = random.choices(seed_data, k=remaining * 2)  # Generate more to increase success rate
        
        retry_results = generate_question_batch(retry_pool, len(exam_questions), progress_callback)
        exam_questions.extend(retry_results[:remaining])

    # Kiá»ƒm tra cÃ¢u trÃ¹ng láº·p dá»±a trÃªn ná»™i dung cÃ¢u há»i (optimized)
    seen_questions = set()
    unique_questions = []
    
    for q in exam_questions:
        question_text = q.get('question', '').strip().lower()
        if question_text and question_text not in seen_questions:
            unique_questions.append(q)
            seen_questions.add(question_text)
    
    exam_questions = unique_questions
    print(f"âœ… Loáº¡i bá» trÃ¹ng láº·p: cÃ²n {len(exam_questions)} cÃ¢u duy nháº¥t")
    
    # Save to cache for future use
    if exam_questions:
        try:
            saved_count = save_questions(exam_questions)
            print(f"ğŸ’¾ ÄÃ£ lÆ°u {saved_count} cÃ¢u vÃ o DB cache")
        except Exception as e:
            print(f"âš ï¸ KhÃ´ng thá»ƒ lÆ°u DB: {e}")
    
    # Fallback: use cache if still not enough
    if len(exam_questions) < num_questions:
        need_fill = num_questions - len(exam_questions)
        print(f"âš ï¸ CÃ²n thiáº¿u {need_fill} cÃ¢u, sá»­ dá»¥ng cache Ä‘á»ƒ bá»• sung...")
        
        cached = get_cached_questions(need_fill * 2, randomize=True)
        for q in cached:
            q_text = q.get('question', '').strip().lower()
            if q_text not in seen_questions:
                exam_questions.append(q)
                seen_questions.add(q_text)
                if len(exam_questions) >= num_questions:
                    break

    # XÃ¡o trá»™n thá»© tá»± cÃ¢u há»i Ä‘á»ƒ Ä‘áº£m báº£o ngáº«u nhiÃªn hoÃ n toÃ n
    random.shuffle(exam_questions)
    
    if len(exam_questions) < num_questions:
        print(f"âš ï¸ Cáº£nh bÃ¡o: Chá»‰ táº¡o Ä‘Æ°á»£c {len(exam_questions)}/{num_questions} cÃ¢u. Vui lÃ²ng kiá»ƒm tra API key hoáº·c thá»­ láº¡i.")
    else:
        print(f"ğŸ‰ Táº¡o xong {len(exam_questions)} cÃ¢u há»i (khÃ´ng trÃ¹ng láº·p, thá»© tá»± ngáº«u nhiÃªn)")
    
    return exam_questions