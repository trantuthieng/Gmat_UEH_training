import google.genai as genai
import json
import os
import random
import re
from difflib import SequenceMatcher
from dotenv import load_dotenv
import time
from db import save_questions, get_cached_questions
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import lru_cache

# Load environment variables
load_dotenv()

# --- C·∫§U H√åNH (Lazy init ƒë·ªÉ kh√¥ng g·ªçi Streamlit tr∆∞·ªõc set_page_config) ---

@lru_cache(maxsize=1)
def _get_api_key() -> str | None:
    """Fetch API key from env first; fallback to Streamlit secrets lazily.
    Avoid accessing streamlit at import time to keep set_page_config as first command.
    """
    key = os.getenv("GEMINI_API_KEY")
    if key:
        return key
    try:
        import streamlit as st  # imported lazily, after app has configured
        return st.secrets.get("GEMINI_API_KEY")
    except Exception:
        return None


@lru_cache(maxsize=1)
def _get_model():
    key = _get_api_key()
    if not key:
        print("GEMINI_API_KEY not found. Set in environment or Streamlit secrets.")
        return None
    try:
        # Create client with API key for google-genai v1.56+
        client = genai.Client(api_key=key)
        return client
    except Exception as e:
        print(f"L·ªói kh·ªüi t·∫°o Gemini: {e}")
        return None

def _clean_response_text(response) -> str:
    """Extracts the first text part and strips code fences/whitespace/control chars."""
    text = None
    try:
        text = response.text
    except Exception:
        pass

    if not text:
        try:
            text = response.candidates[0].content.parts[0].text  # best-effort fallback
        except Exception:
            text = ""

    # Remove markdown code fences
    text = text.replace('```json', '').replace('```', '').strip()
    
    # Remove control characters that break JSON (except \n, \r, \t)
    import re
    text = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', text)
    
    return text

def _align_correct_answer(options: list, correct_answer: str) -> str | None:
    """Best-effort map correct_answer to one of the provided options.

    - Accept exact match
    - Accept letter prefix match (A/B/C/D)
    - Accept content match after stripping prefixes like "A." or "A)"
    - Fallback to similarity score to handle minor variations
    """
    if not options or not correct_answer:
        return None

    cleaned_opts = []
    seen = set()
    for opt in options:
        if not isinstance(opt, str):
            continue
        opt_clean = opt.strip()
        if opt_clean and opt_clean not in seen:
            cleaned_opts.append(opt_clean)
            seen.add(opt_clean)

    if not cleaned_opts:
        return None

    correct_clean = correct_answer.strip()

    # 1) Exact match
    for opt in cleaned_opts:
        if correct_clean == opt:
            return opt

    # Helper to strip letter prefix
    def strip_prefix(val: str) -> str:
        return re.sub(r'^[A-D][\.\)]\s*', '', (val or '').strip(), flags=re.IGNORECASE)

    # 2) Match by letter prefix (A/B/C/D)
    if correct_clean:
        letter = correct_clean[:1].upper()
        if letter in "ABCD":
            for opt in cleaned_opts:
                if opt.upper().startswith(letter):
                    return opt

    # 3) Match by content after removing prefix
    normalized_correct = strip_prefix(correct_clean).lower()
    if normalized_correct:
        for opt in cleaned_opts:
            if strip_prefix(opt).lower() == normalized_correct:
                return opt

    # 4) Fallback: similarity match
    best_opt, best_ratio = None, 0.0
    for opt in cleaned_opts:
        ratio = SequenceMatcher(None, strip_prefix(opt).lower(), normalized_correct).ratio()
        if ratio > best_ratio:
            best_opt, best_ratio = opt, ratio
    if best_opt and best_ratio >= 0.8:
        return best_opt

    return None


def generate_question_variant(seed_question, max_attempts: int = 3):
    """T·∫°o 1 bi·∫øn th·ªÉ c√¢u h·ªèi (d√πng cho h√†m batch b√™n d∆∞·ªõi) v·ªõi retry khi JSON l·ªói."""
    model = _get_model()
    if model is None:
        print("‚ùå Model kh√¥ng ƒë∆∞·ª£c kh·ªüi t·∫°o")
        return None

    topic = seed_question.get('topic', 'Ki·∫øn th·ª©c t·ªïng h·ª£p')
    is_visual = topic.lower() in ['pattern recognition', 'letter pattern', 'logic puzzle', 'number pattern']
    
    prompt = f"""
    B·∫°n l√† chuy√™n gia ra ƒë·ªÅ thi GMAT cao c·∫•p.
    Ch·ªß ƒë·ªÅ: {topic}
    C√¢u m·∫´u: "{seed_question['content']}"

    Nhi·ªám v·ª•: T·∫°o 1 c√¢u h·ªèi tr·∫Øc nghi·ªám M·ªöI d·ª±a tr√™n logic c·ªßa c√¢u m·∫´u:
    1. To√°n h·ªçc: Thay ƒë·ªïi s·ªë li·ªáu nh∆∞ng PH·∫¢I T·ª∞ T√çNH TO√ÅN L·∫†I ƒê√ÅP √ÅN ch√≠nh x√°c.
    2. Logic: Gi·ªØ c·∫•u tr√∫c suy lu·∫≠n, thay ƒë·ªïi ng·ªØ c·∫£nh.
    3. Pattern: T·∫°o quy lu·∫≠t m·ªõi r√µ r√†ng.

    Y√äU C·∫¶U QUAN TR·ªåNG (b·∫Øt bu·ªôc):
    - H√£y suy nghƒ© t·ª´ng b∆∞·ªõc (Chain of Thought) v√† ghi r√µ ph√©p t√≠nh s·ªë h·ªçc c·ª• th·ªÉ (kh√¥ng n√≥i chung chung).
    - step_by_step_thinking ph·∫£i c√≥ d·∫°ng "B∆∞·ªõc 1: ... B∆∞·ªõc 2: ..." k√®m s·ªë li·ªáu, c√¥ng th·ª©c v√† k·∫øt qu·∫£ trung gian. ƒê·ª¶ CHI TI·∫æT, ƒê·∫¶Y ƒê·ª¶.
    - explanation: CH·ªà ghi k·∫øt qu·∫£ cu·ªëi c√πng + l√Ω do T·∫†I SAO l√† ƒë√°p √°n ƒë√∫ng (KH√îNG l·∫∑p l·∫°i c√¥ng th·ª©c, KH√îNG l·∫∑p l·∫°i c√°c b∆∞·ªõc t√≠nh - nh·ªØng c√°i ƒë√≥ ƒë√£ c√≥ ·ªü step_by_step_thinking).
    - ƒê√°p √°n ƒë√∫ng (correct_answer) PH·∫¢I n·∫±m trong danh s√°ch l·ª±a ch·ªçn (options).
    - Tr·∫£ v·ªÅ k·∫øt qu·∫£ d∆∞·ªõi d·∫°ng JSON thu·∫ßn t√∫y, kh√¥ng c√≥ markdown.
    - CH·ªà tr·∫£ v·ªÅ 5 tr∆∞·ªùng: question, options, step_by_step_thinking, correct_answer, explanation. KH√îNG th√™m b·∫•t k·ª≥ tr∆∞·ªùng hay ph·∫ßn gi·∫£i th√≠ch n√†o kh√°c.

    OUTPUT JSON FORMAT (B·∫Øt bu·ªôc tu√¢n th·ªß ch√≠nh x√°c):
    {{
        "question": "N·ªôi dung c√¢u h·ªèi...",
        "options": ["A. ...", "B. ...", "C. ...", "D. ..."],
        "step_by_step_thinking": "B∆∞·ªõc 1: ...; B∆∞·ªõc 2: ... (ghi r√µ ph√©p t√≠nh v√† k·∫øt qu·∫£ trung gian)",
        "correct_answer": "Ch√©p y nguy√™n text c·ªßa l·ª±a ch·ªçn ƒë√∫ng v√†o ƒë√¢y",
        "explanation": "T√≥m t·∫Øt v√¨ sao ƒë√°p √°n ƒë√∫ng, nh·∫Øc l·∫°i c√¥ng th·ª©c/suy lu·∫≠n ch√≠nh v√† s·ªë k·∫øt qu·∫£"
    }}
    """

    for attempt in range(1, max_attempts + 1):
        try:
            # Call generate_content with google-genai Client API
            response = model.models.generate_content(
                model='gemini-2.5-pro',
                contents=prompt,
                config={
                    'temperature': 0.7,
                    'max_output_tokens': 8192
                }
            )
            clean_text = _clean_response_text(response)
            data = json.loads(clean_text)
            print(f"‚úÖ T·∫°o c√¢u h·ªèi th√†nh c√¥ng (attempt {attempt})")
            
            # --- S·ª¨A L·ªñI: Gi·ªØ nguy√™n metadata t·ª´ c√¢u g·ªëc ---
            data['type'] = seed_question.get('type', 'general')  # Gi·ªØ nguy√™n type c·ªßa c√¢u g·ªëc (math/logic)
            data['topic'] = topic  # QUAN TR·ªåNG: G√°n l·∫°i topic ƒë·ªÉ l∆∞u v√†o DB
            data['image_url'] = seed_question.get('image_url')  # Gi·ªØ link ·∫£nh n·∫øu c√¢u g·ªëc c√≥
            # -------------------------------------------

            # ƒê·∫£m b·∫£o ƒë√°p √°n kh·ªõp v·ªõi m·ªôt l·ª±a ch·ªçn
            options = data.get('options') or []
            correct = data.get('correct_answer') or ''
            print(f"üîç ƒêang ki·ªÉm tra ƒë√°p √°n: {correct[:50]}...")
            aligned = _align_correct_answer(options, correct)
            if not aligned:
                raise ValueError("Correct answer does not align with options")
            print(f"‚úì ƒê√°p √°n h·ª£p l·ªá v√† kh·ªõp v·ªõi l·ª±a ch·ªçn")

            # Chu·∫©n h√≥a l·∫°i danh s√°ch l·ª±a ch·ªçn v√† ƒë√°p √°n ƒë·ªÉ hi·ªÉn th·ªã nh·∫•t qu√°n
            cleaned_opts = []
            seen = set()
            for opt in options:
                if not isinstance(opt, str):
                    continue
                opt_clean = opt.strip()
                if opt_clean and opt_clean not in seen:
                    cleaned_opts.append(opt_clean)
                    seen.add(opt_clean)

            data['options'] = cleaned_opts
            data['correct_answer'] = aligned
            print(f"‚úÖ Ho√†n t·∫•t ki·ªÉm tra c√¢u h·ªèi - Topic: {topic}, S·ªë l·ª±a ch·ªçn: {len(cleaned_opts)}")
            return data
        except json.JSONDecodeError as e:
            print(f"‚ùå L·ªói JSON (attempt {attempt}/{max_attempts}): {e}")
            print(f"Response text: {clean_text[:200]}")
            if attempt < max_attempts:
                time.sleep(1 * attempt)  # Exponential backoff
        except Exception as e:
            print(f"‚ùå L·ªói khi t·∫°o c√¢u (attempt {attempt}/{max_attempts}): {e}")
            if attempt < max_attempts:
                time.sleep(2 * attempt)  # Exponential backoff

    return None

def generate_question_batch(seeds, start_idx=0, progress_callback=None):
    """Generate multiple questions concurrently"""
    results = []
    visual_keywords = ['h√¨nh', 'shape', '·∫£nh', 'diagram', 'figure', 'bi·ªÉu ƒë·ªì']

    def _extract_number(text: str) -> float | None:
        nums = re.findall(r"\d+(?:[.,]\d+)?", text or "")
        if len(nums) < 2:
            return None
        try:
            old_v = float(nums[0].replace(',', '.'))
            new_v = float(nums[1].replace(',', '.'))
            if old_v == 0:
                return None
            pct = round((new_v - old_v) / old_v * 100, 2)
            return pct
        except Exception:
            return None

    def _is_percent_increase_question(text: str) -> bool:
        t = (text or '').lower()
        return 'tƒÉng' in t and 't·ª´' in t and ('l√™n' in t or 'th√†nh' in t)

    def _percent_answer_matches(q: dict) -> bool:
        question = q.get('question', '')
        if not _is_percent_increase_question(question):
            return True  # not a percent-change question
        expected = _extract_number(question)
        if expected is None:
            return True

        def _first_number(val: str) -> float | None:
            m = re.search(r"-?\d+(?:[.,]\d+)?", val or "")
            if not m:
                return None
            try:
                return float(m.group(0).replace(',', '.'))
            except Exception:
                return None

        options = q.get('options') or []
        correct = q.get('correct_answer') or ''
        correct_num = _first_number(correct)
        # Accept if correct_answer has number close to expected
        if correct_num is not None and abs(correct_num - expected) <= 0.6:
            return True
        # Else check if any option matches expected closely
        for opt in options:
            num = _first_number(opt)
            if num is not None and abs(num - expected) <= 0.6:
                return True
        return False

    def _is_valid(q: dict) -> bool:
        """Basic sanity checks to avoid garbage answers."""
        if not q:
            return False
        options = q.get('options') or []
        if len(options) < 2:
            return False
        correct = q.get('correct_answer') or ''
        has_option_match = False
        # Accept if exact match to an option
        if correct in options:
            has_option_match = True
        # Accept if the letter prefix matches one option's prefix (e.g., 'A.' or 'A ')
        if correct:
            letter = correct.strip()[:2]  # e.g., "A." or "A "
            for opt in options:
                if opt.strip().startswith(letter):
                    has_option_match = True
        if not has_option_match:
            return False
        # Additional semantic check for percent-increase questions
        if not _percent_answer_matches(q):
            return False
        return True
    
    # Gi·∫£m concurrency ƒë·ªÉ tr√°nh l·ªói 429 (gi·ªõi h·∫°n ~7 RPM t√†i kho·∫£n hi·ªán t·∫°i)
    with ThreadPoolExecutor(max_workers=1) as executor:
        # Submit all tasks
        future_to_idx = {executor.submit(generate_question_variant, seed): (idx, seed) 
                        for idx, seed in enumerate(seeds)}
        
        # Process completed tasks
        for future in as_completed(future_to_idx):
            idx, seed = future_to_idx[future]
            try:
                new_q = future.result()
                if new_q:
                    text = (new_q.get('question') or '').lower()
                    has_image = bool(new_q.get('image_url'))
                    if any(k in text for k in visual_keywords) and not has_image:
                        print(f"üö´ B·ªè qua c√¢u h·ªèi thi·∫øu h√¨nh ·∫£nh: {text[:60]}...")
                    elif not _is_valid(new_q):
                        print(f"üö´ B·ªè qua c√¢u h·ªèi sai ƒë·ªãnh d·∫°ng ƒë√°p √°n")
                    else:
                        results.append(new_q)
                        print(f"‚úÖ C√¢u {start_idx + idx + 1} - T·∫°o th√†nh c√¥ng")
                else:
                    print(f"‚ö†Ô∏è C√¢u {start_idx + idx + 1} - Th·∫•t b·∫°i")
            except Exception as e:
                print(f"‚ùå L·ªói khi t·∫°o c√¢u {start_idx + idx + 1}: {e}")

            # TƒÉng l√™n 15s ƒë·ªÉ an to√†n h∆°n v·ªõi gi·ªõi h·∫°n API
            # 60s / 15s = 4 requests/ph√∫t (r·∫•t an to√†n, tr√°nh qu√° t·∫£i)
            print(f"‚è≥ Ch·ªù 15s tr∆∞·ªõc khi t·∫°o c√¢u ti·∫øp theo...")
            time.sleep(15)
            
            if progress_callback:
                progress_callback((start_idx + idx + 1) / (start_idx + len(seeds)))
    
    return results

def generate_full_exam(seed_data, num_questions=30, num_general=0, progress_callback=None, max_retries_per_question=4, user_id=None):
    """
    T·∫°o b·ªô ƒë·ªÅ thi: Tr·ªôn 50% c√¢u h·ªèi c≈© t·ª´ Cache v√† 50% c√¢u h·ªèi m·ªõi t·ª´ AI.
    ∆Øu ti√™n c√°c topic m√† user hay tr·∫£ l·ªùi sai (n·∫øu c√≥ user_id).
    
    Args:
        user_id: ID c·ªßa user ƒë·ªÉ l·∫•y weak topics (optional)
    """
    exam_questions = []

    if not seed_data:
        print("‚ùå Kh√¥ng c√≥ seed data")
        return exam_questions

    # 1. C·∫§U H√åNH T·ªà L·ªÜ (50% c≈© - 50% m·ªõi)
    target_cached = int(num_questions * 0.5)  # 15 c√¢u c≈©
    target_new = num_questions - target_cached # 15 c√¢u m·ªõi

    print(f"üìã K·∫ø ho·∫°ch t·∫°o ƒë·ªÅ: {target_cached} c√¢u c≈© (DB) + {target_new} c√¢u m·ªõi (AI)")
    
    # 1.5 L·∫§Y WEAK TOPICS N·∫æU C√ì USER_ID
    weak_topics = []
    weak_topic_boost_ratio = 0.3  # 30% c√¢u s·∫Ω ∆∞u ti√™n weak topics
    if user_id:
        try:
            from db import get_weak_topics
            weak_topics_data = get_weak_topics(user_id, limit=5)
            weak_topics = [item['topic'] for item in weak_topics_data]
            if weak_topics:
                print(f"üéØ Ph√°t hi·ªán ƒëi·ªÉm y·∫øu: {', '.join(weak_topics)}")
        except Exception as e:
            print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ l·∫•y weak topics: {e}")

    # 2. L·∫§Y C√ÇU H·ªéI T·ª™ CACHE (DB)
    cached_part = get_cached_questions(target_cached, randomize=True)
    if cached_part:
        print(f"‚úÖ ƒê√£ l·∫•y {len(cached_part)} c√¢u t·ª´ Cache")
        exam_questions.extend(cached_part)
    
    # T√≠nh s·ªë c√¢u th·ª±c s·ª± c·∫ßn t·∫°o m·ªõi (ph√≤ng tr∆∞·ªùng h·ª£p DB ch∆∞a c√≥ g√¨ th√¨ ph·∫£i t·∫°o h·∫øt)
    actual_needed_new = num_questions - len(exam_questions)
    
    if actual_needed_new > 0:
        print(f"ü§ñ ƒêang AI t·∫°o m·ªõi {actual_needed_new} c√¢u...")
        print(f"‚è±Ô∏è  Th·ªùi gian ∆∞·ªõc t√≠nh: ~{actual_needed_new * 15 / 60:.1f} ph√∫t (15s/c√¢u)")
        
        # --- CH·ªåN SEED DATA V·ªöI ∆ØU TI√äN WEAK TOPICS ---
        topic_buckets = {}
        for s in seed_data:
            t = s.get('topic', 'general')
            topic_buckets.setdefault(t, []).append(s)
        
        selected_seeds = []
        
        # ∆Øu ti√™n weak topics tr∆∞·ªõc (30% s·ªë c√¢u)
        if weak_topics:
            weak_count = int(actual_needed_new * weak_topic_boost_ratio)
            for topic in weak_topics:
                if topic in topic_buckets and len(selected_seeds) < weak_count:
                    # L·∫•y nhi·ªÅu c√¢u t·ª´ topic y·∫øu
                    available = topic_buckets[topic]
                    take = min(len(available), weak_count - len(selected_seeds))
                    selected_seeds.extend(random.sample(available, take))
            print(f"‚úÖ ƒê√£ th√™m {len(selected_seeds)} c√¢u t·ª´ weak topics")
        
        # Ph·∫ßn c√≤n l·∫°i ch·ªçn ƒëa d·∫°ng t·ª´ c√°c topic kh√°c
        remaining_needed = actual_needed_new - len(selected_seeds)
        bucket_list = list(topic_buckets.values())
        random.shuffle(bucket_list)
        
        while len(selected_seeds) < actual_needed_new and bucket_list:
            for bucket in bucket_list:
                if bucket:
                    selected_seeds.append(random.choice(bucket))
                    if len(selected_seeds) >= actual_needed_new:
                        break
        # Fallback
        if len(selected_seeds) < actual_needed_new:
            selected_seeds.extend(random.choices(seed_data, k=actual_needed_new - len(selected_seeds)))

        # --- G·ªåI API T·∫†O C√ÇU M·ªöI (D√πng h√†m batch ƒë√£ t·ªëi ∆∞u ·ªü b∆∞·ªõc tr∆∞·ªõc) ---
        newly_generated = generate_question_batch(selected_seeds, 0, progress_callback)
        
        # L∆∞u c√¢u M·ªöI v√†o DB ngay l·∫≠p t·ª©c
        if newly_generated:
            try:
                saved = save_questions(newly_generated)
                print(f"üíæ ƒê√£ l∆∞u {saved} c√¢u m·ªõi v√†o DB")
            except Exception as e:
                print(f"‚ö†Ô∏è L·ªói l∆∞u DB: {e}")
            
            exam_questions.extend(newly_generated)

    # 3. KI·ªÇM TRA V√Ä B·ªî SUNG N·∫æU THI·∫æU (FALLBACK)
    if len(exam_questions) < num_questions:
        missing = num_questions - len(exam_questions)
        print(f"‚ö†Ô∏è V·∫´n thi·∫øu {missing} c√¢u, l·∫•y th√™m t·ª´ Cache b√π v√†o...")
        extra_cached = get_cached_questions(limit=100, randomize=True)
        
        existing_hashes = set()
        for q in exam_questions:
            h = (q.get('question', '') + q.get('correct_answer', '')).strip().lower()
            existing_hashes.add(h)
            
        for q in extra_cached:
            h = (q.get('question', '') + q.get('correct_answer', '')).strip().lower()
            if h not in existing_hashes:
                exam_questions.append(q)
                if len(exam_questions) >= num_questions:
                    break

    # 4. X√ÅO TR·ªòN CU·ªêI C√ôNG
    random.shuffle(exam_questions)
    
    print(f"üéâ Ho√†n t·∫•t ƒë·ªÅ thi: {len(exam_questions)} c√¢u.")
    return exam_questions[:num_questions]